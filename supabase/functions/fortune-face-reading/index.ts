import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.39.0'
import OpenAI from 'https://esm.sh/openai@4.20.1'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const {
      image,
      instagram_url,
      analysis_source,
      include_fortune = true,
      userId,
      userName,
      userBirthDate,
      userBirthTime,
      userGender
    } = await req.json()

    console.log('ğŸ“¸ Face reading request received:', {
      hasImage: !!image,
      hasInstagramUrl: !!instagram_url,
      analysisSource: analysis_source,
      userId
    })

    // Initialize OpenAI
    const openai = new OpenAI({
      apiKey: Deno.env.get('OPENAI_API_KEY')!,
    })

    // Initialize Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    const supabase = createClient(supabaseUrl, supabaseServiceKey)

    let imageData: string | null = null

    // Handle different image sources
    if (analysis_source === 'instagram' && instagram_url) {
      // For Instagram URLs, we might need to fetch the image
      // This is a placeholder - actual implementation would need Instagram API
      throw new Error('Instagram URL analysis not yet implemented')
    } else if (image) {
      imageData = image
    }

    if (!imageData) {
      throw new Error('No image data provided')
    }

    // Create the face reading prompt
    const faceReadingPrompt = `ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „í†µ ê´€ìƒí•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì–¼êµ´ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ ê´€ìƒ ë¶„ì„ê³¼ ìš´ì„¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì •ë³´:
- ì´ë¦„: ${userName || 'ê·€í•˜'}
- ì„±ë³„: ${userGender === 'male' ? 'ë‚¨ì„±' : userGender === 'female' ? 'ì—¬ì„±' : 'ì•Œ ìˆ˜ ì—†ìŒ'}
${userBirthDate ? `- ìƒë…„ì›”ì¼: ${userBirthDate}` : ''}
${userBirthTime ? `- ìƒì‹œ: ${userBirthTime}` : ''}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê´€ìƒ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì „ì²´ì ì¸ ì¸ìƒ** (ì „ë°˜ì ì¸ ì–¼êµ´ ì¸ìƒê³¼ ê¸°ìš´)
   - ì²«ì¸ìƒê³¼ ì „ì²´ì ì¸ ì—ë„ˆì§€
   - ì–¼êµ´í˜•ê³¼ ê·¸ ì˜ë¯¸
   - ì „ë°˜ì ì¸ ë³µì˜ ì •ë„

2. **ì£¼ìš” ë¶€ìœ„ë³„ ë¶„ì„**
   - ì´ë§ˆ (ê´€ë¡ê¶): ì§€í˜œ, í•™ì—…ìš´, ì¶œì„¸ìš´
   - ëˆˆì¹ (í˜•ì œê¶): ì¸ê°„ê´€ê³„, í˜•ì œìš´
   - ëˆˆ (ì²˜ìê¶): ë°°ìš°ììš´, ìë…€ìš´, ê°ì •
   - ì½” (ì¬ë°±ê¶): ì¬ë¬¼ìš´, ê¸ˆì „ìš´
   - ì… (ì‹ë¡ê¶): ì‹ë³µ, ë§ë³µ, ìƒí™œìš´
   - í„± (ë…¸ë…„ê¶): ë…¸í›„ìš´, ê±´ê°•ìš´
   - ê·€ (ë³µë•ê¶): ì „ë°˜ì ì¸ ë³µ, ì¥ìˆ˜ìš´
   - ê´‘ëŒ€ë¼ˆ: ê¶Œë ¥ìš´, ë¦¬ë”ì‹­

3. **ì„±ê²©ê³¼ ê¸°ì§ˆ**
   - íƒ€ê³ ë‚œ ì„±ê²© íŠ¹ì„±
   - ê°•ì ê³¼ ì•½ì 
   - ëŒ€ì¸ê´€ê³„ ìŠ¤íƒ€ì¼

4. **ìš´ì„¸ ë¶„ì„**
   - ğŸ’° ì¬ë¬¼ìš´: ê¸ˆì „ìš´ê³¼ ì‚¬ì—…ìš´
   - â¤ï¸ ì• ì •ìš´: ì—°ì• ìš´ê³¼ ê²°í˜¼ìš´
   - ğŸ’¼ ì§ì—…ìš´: ì ì„±ê³¼ ì„±ê³µ ê°€ëŠ¥ì„±
   - ğŸ¥ ê±´ê°•ìš´: ì£¼ì˜í•´ì•¼ í•  ê±´ê°• ì‚¬í•­
   - ğŸ€ ì´ìš´: ì „ë°˜ì ì¸ í–‰ìš´ë„

5. **íŠ¹ë³„í•œ ê´€ìƒ íŠ¹ì§•**
   - ë³µì´ ë§ì€ ê´€ìƒ í¬ì¸íŠ¸
   - ê°œì„ í•˜ë©´ ì¢‹ì„ ì 
   - ìˆ¨ê²¨ì§„ ì¬ëŠ¥ì´ë‚˜ ê°€ëŠ¥ì„±

6. **ì¡°ì–¸ê³¼ ê°œìš´ë²•**
   - ìš´ì„ ë†’ì´ëŠ” ë°©ë²•
   - í”¼í•´ì•¼ í•  ê²ƒë“¤
   - í–‰ìš´ì˜ ìƒ‰ìƒ, ë°©í–¥, ìˆ«ì

ëª¨ë“  ë¶„ì„ì€ ê¸ì •ì ì´ê³  í¬ë§ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ë˜, êµ¬ì²´ì ì´ê³  ê°œì¸í™”ëœ ë‚´ìš©ì„ ì œê³µí•˜ì„¸ìš”.
ì „í†µ ê´€ìƒí•™ì˜ ì§€í˜œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜ë˜, í˜„ëŒ€ì ì¸ í•´ì„ì„ ê°€ë¯¸í•˜ì—¬ ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.`

    // Call OpenAI Vision API
    const completion = await openai.chat.completions.create({
      model: "gpt-5-nano-2025-08-07",
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: faceReadingPrompt },
            {
              type: "image_url",
              image_url: {
                url: `data:image/jpeg;base64,${imageData}`,
                detail: "high"
              }
            }
          ]
        }
      ],
      max_tokens: 2000,
      temperature: 0.8,
    })

    const analysisResult = completion.choices[0].message.content

    if (!analysisResult) {
      throw new Error('Failed to generate face reading analysis')
    }

    // Parse the analysis result into structured format
    const sections = analysisResult.split(/\d+\.\s\*\*/).filter(s => s.trim())

    // Extract key information for the response
    const mainFortune = extractSection(analysisResult, 'ì „ì²´ì ì¸ ì¸ìƒ') ||
                       'ë‹¹ì‹ ì˜ ì–¼êµ´ì—ì„œ ë°ì€ ê¸°ìš´ì´ ëŠê»´ì§‘ë‹ˆë‹¤.'

    const luckScore = Math.floor(Math.random() * 20) + 70 // 70-90 range

    // Extract different fortune categories
    const wealthFortune = extractSection(analysisResult, 'ì¬ë¬¼ìš´') ||
                         'ì¬ë¬¼ìš´ì´ ìƒìŠ¹í•˜ëŠ” ì‹œê¸°ì…ë‹ˆë‹¤.'
    const loveFortune = extractSection(analysisResult, 'ì• ì •ìš´') ||
                       'ì¸ì—°ì´ ë‹¤ê°€ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.'
    const healthFortune = extractSection(analysisResult, 'ê±´ê°•ìš´') ||
                         'ê±´ê°• ê´€ë¦¬ì— ì‹ ê²½ì“°ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ìˆì„ ê²ƒì…ë‹ˆë‹¤.'
    const careerFortune = extractSection(analysisResult, 'ì§ì—…ìš´') ||
                         'ìƒˆë¡œìš´ ê¸°íšŒê°€ ì°¾ì•„ì˜¬ ê²ƒì…ë‹ˆë‹¤.'

    // Format the response
    const fortuneResponse = {
      fortuneType: 'face-reading',
      mainFortune: mainFortune,
      details: {
        face_type: extractFaceType(analysisResult),
        overall_fortune: mainFortune,
        personality: extractSection(analysisResult, 'ì„±ê²©ê³¼ ê¸°ì§ˆ'),
        wealth_fortune: wealthFortune,
        love_fortune: loveFortune,
        health_fortune: healthFortune,
        career_fortune: careerFortune,
        special_features: extractSection(analysisResult, 'íŠ¹ë³„í•œ ê´€ìƒ íŠ¹ì§•'),
        advice: extractSection(analysisResult, 'ì¡°ì–¸ê³¼ ê°œìš´ë²•'),
        full_analysis: analysisResult
      },
      luckScore: luckScore,
      timestamp: new Date().toISOString()
    }

    // Save to database if user is logged in
    if (userId) {
      const { error: insertError } = await supabase
        .from('fortunes')
        .insert({
          user_id: userId,
          type: 'face-reading',
          result: fortuneResponse,
          metadata: {
            analysis_source,
            has_image: true
          }
        })

      if (insertError) {
        console.error('Error saving fortune:', insertError)
      }
    }

    return new Response(
      JSON.stringify(fortuneResponse),
      {
        headers: {
          ...corsHeaders,
          'Content-Type': 'application/json'
        }
      }
    )

  } catch (error) {
    console.error('Error in face-reading function:', error)

    return new Response(
      JSON.stringify({
        error: error.message || 'Failed to analyze face',
        details: error.toString()
      }),
      {
        status: 500,
        headers: {
          ...corsHeaders,
          'Content-Type': 'application/json'
        }
      }
    )
  }
})

// Helper function to extract sections from the analysis
function extractSection(text: string, sectionName: string): string | null {
  const regex = new RegExp(`${sectionName}[^:]*:([^\\n]+(?:\\n(?![\\d]+\\.|\\*\\*)[^\\n]+)*)`, 'i')
  const match = text.match(regex)
  if (match && match[1]) {
    return match[1].trim().replace(/^\s*[-â€¢]\s*/, '')
  }

  // Try alternative format
  const altRegex = new RegExp(`\\*\\*${sectionName}\\*\\*[^:]*:?\\s*([^\\n]+)`, 'i')
  const altMatch = text.match(altRegex)
  if (altMatch && altMatch[1]) {
    return altMatch[1].trim()
  }

  return null
}

// Helper function to extract face type
function extractFaceType(text: string): string {
  const faceTypes = ['ë‘¥ê·¼í˜•', 'íƒ€ì›í˜•', 'ê°ì§„í˜•', 'í•˜íŠ¸í˜•', 'ê¸´í˜•', 'ì—­ì‚¼ê°í˜•']
  for (const type of faceTypes) {
    if (text.includes(type)) {
      return type + ' ì–¼êµ´'
    }
  }
  return 'ì¡°í™”ë¡œìš´ ì–¼êµ´í˜•'
}