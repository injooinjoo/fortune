/**
 * Wikipedia ì—°ì˜ˆì¸ ì •ë³´ í¬ë¡¤ë§ Edge Function
 *
 * @description Wikipedia APIë¥¼ í†µí•´ ì—°ì˜ˆì¸ ì •ë³´(ì¶œìƒì¼, ì§ì—… ë“±)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
 *
 * @endpoint POST /crawl-celebrity-wikipedia
 *
 * @requestBody
 * - celebrity_id: string - í¬ë¡¤ë§í•  ì—°ì˜ˆì¸ ID
 * - name: string - ì—°ì˜ˆì¸ ì´ë¦„ (ê²€ìƒ‰ìš©)
 * - batch_size?: number - ë°°ì¹˜ í¬ë¡¤ë§ ì‹œ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ (ê¸°ë³¸ 10)
 * - mode?: 'single' | 'batch' - ë‹¨ì¼ ë˜ëŠ” ë°°ì¹˜ ëª¨ë“œ
 *
 * @response
 * - success: boolean
 * - data: CrawledData
 */
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.39.3'

interface CrawledData {
  birth_date?: string
  birth_place?: string
  occupation?: string
  description?: string
  image_url?: string
  raw_data?: Record<string, unknown>
}

interface RequestBody {
  celebrity_id?: string
  name?: string
  batch_size?: number
  mode?: 'single' | 'batch'
}

interface WikiSearchResult {
  query?: {
    search?: Array<{ title: string; pageid: number }>
  }
}

interface WikiPageResult {
  query?: {
    pages?: Record<string, {
      title: string
      extract?: string
      thumbnail?: { source: string }
      pageprops?: { wikibase_item?: string }
    }>
  }
}

interface WikidataResult {
  entities?: Record<string, {
    claims?: Record<string, Array<{
      mainsnak?: {
        datavalue?: {
          value?: unknown
          type?: string
        }
      }
    }>>
  }>
}

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

// Wikipedia APIë¡œ ê²€ìƒ‰
async function searchWikipedia(name: string): Promise<string | null> {
  const encodedName = encodeURIComponent(name)
  const url = `https://ko.wikipedia.org/w/api.php?action=query&list=search&srsearch=${encodedName}&format=json&utf8=1`

  try {
    const response = await fetch(url, {
      headers: { 'Accept': 'application/json' }
    })

    if (!response.ok) return null

    const data: WikiSearchResult = await response.json()
    const results = data.query?.search

    if (!results || results.length === 0) {
      // í•œêµ­ì–´ ìœ„í‚¤ ì‹¤íŒ¨ ì‹œ ì˜ì–´ ìœ„í‚¤ ì‹œë„
      const enUrl = `https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch=${encodedName}&format=json&utf8=1`
      const enResponse = await fetch(enUrl, {
        headers: { 'Accept': 'application/json' }
      })

      if (!enResponse.ok) return null

      const enData: WikiSearchResult = await enResponse.json()
      const enResults = enData.query?.search

      if (!enResults || enResults.length === 0) return null
      return `en:${enResults[0].title}`
    }

    return results[0].title
  } catch (error) {
    console.error(`Wikipedia ê²€ìƒ‰ ì˜¤ë¥˜ (${name}):`, error)
    return null
  }
}

// Wikipedia í˜ì´ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
async function getWikipediaPage(title: string): Promise<CrawledData> {
  const result: CrawledData = { raw_data: {} }

  try {
    // ì–¸ì–´ í™•ì¸
    let lang = 'ko'
    let actualTitle = title
    if (title.startsWith('en:')) {
      lang = 'en'
      actualTitle = title.substring(3)
    }

    const encodedTitle = encodeURIComponent(actualTitle)
    const url = `https://${lang}.wikipedia.org/w/api.php?action=query&titles=${encodedTitle}&prop=extracts|pageprops|pageimages&exintro=1&explaintext=1&pithumbsize=300&format=json&utf8=1`

    const response = await fetch(url, {
      headers: { 'Accept': 'application/json' }
    })

    if (!response.ok) return result

    const data: WikiPageResult = await response.json()
    const pages = data.query?.pages

    if (!pages) return result

    const pageId = Object.keys(pages)[0]
    if (pageId === '-1') return result

    const page = pages[pageId]

    result.description = page.extract?.substring(0, 500)
    result.image_url = page.thumbnail?.source

    // Wikidata IDê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ ì¡°íšŒ
    const wikidataId = page.pageprops?.wikibase_item
    if (wikidataId) {
      const wikidataInfo = await getWikidataInfo(wikidataId)
      Object.assign(result, wikidataInfo)
    }

    result.raw_data = { title: page.title, wikidataId }

  } catch (error) {
    console.error('Wikipedia í˜ì´ì§€ ì¡°íšŒ ì˜¤ë¥˜:', error)
  }

  return result
}

// Wikidataì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
async function getWikidataInfo(wikidataId: string): Promise<Partial<CrawledData>> {
  const result: Partial<CrawledData> = {}

  try {
    const url = `https://www.wikidata.org/w/api.php?action=wbgetentities&ids=${wikidataId}&props=claims&format=json`

    const response = await fetch(url, {
      headers: { 'Accept': 'application/json' }
    })

    if (!response.ok) return result

    const data: WikidataResult = await response.json()
    const entity = data.entities?.[wikidataId]

    if (!entity?.claims) return result

    // P569 = ìƒë…„ì›”ì¼
    const birthDate = entity.claims['P569']?.[0]?.mainsnak?.datavalue?.value
    if (birthDate && typeof birthDate === 'object' && 'time' in birthDate) {
      const timeStr = (birthDate as { time: string }).time
      // +1993-05-16T00:00:00Z í˜•ì‹ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
      const match = timeStr.match(/\+?(\d{4})-(\d{2})-(\d{2})/)
      if (match) {
        result.birth_date = `${match[1]}-${match[2]}-${match[3]}`
      }
    }

    // P19 = ì¶œìƒì§€ (IDë¡œ ë°˜í™˜ë˜ë¯€ë¡œ ì¶”ê°€ ì¡°íšŒ í•„ìš”)
    const birthPlaceId = entity.claims['P19']?.[0]?.mainsnak?.datavalue?.value
    if (birthPlaceId && typeof birthPlaceId === 'object' && 'id' in birthPlaceId) {
      const placeId = (birthPlaceId as { id: string }).id
      result.birth_place = placeId // ë‚˜ì¤‘ì— ë¼ë²¨ ì¡°íšŒ ê°€ëŠ¥
    }

    // P106 = ì§ì—…
    const occupation = entity.claims['P106']?.[0]?.mainsnak?.datavalue?.value
    if (occupation && typeof occupation === 'object' && 'id' in occupation) {
      result.occupation = (occupation as { id: string }).id
    }

  } catch (error) {
    console.error('Wikidata ì¡°íšŒ ì˜¤ë¥˜:', error)
  }

  return result
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    const supabase = createClient(supabaseUrl, serviceRoleKey)

    const body: RequestBody = await req.json()
    const { celebrity_id, name, batch_size = 10, mode = 'single' } = body

    // ë°°ì¹˜ ëª¨ë“œ
    if (mode === 'batch') {
      const { data: celebrities, error: fetchError } = await supabase
        .from('celebrities')
        .select('id, name')
        .eq('crawl_status', 'pending')
        .order('popularity_score', { ascending: false })
        .limit(batch_size)

      if (fetchError) {
        throw new Error(`ì¡°íšŒ ì˜¤ë¥˜: ${fetchError.message}`)
      }

      if (!celebrities || celebrities.length === 0) {
        return new Response(
          JSON.stringify({ success: true, message: 'í¬ë¡¤ë§ ëŒ€ê¸° í•­ëª© ì—†ìŒ', processed: 0 }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        )
      }

      console.log(`ğŸ“¥ Wikipedia ë°°ì¹˜ ì¡°íšŒ ì‹œì‘: ${celebrities.length}ëª…`)

      const results = []
      for (const celeb of celebrities) {
        // Rate limiting: 500ms ëŒ€ê¸° (Wikipedia APIëŠ” ë” ê´€ëŒ€í•¨)
        await new Promise(resolve => setTimeout(resolve, 500))

        // ìƒíƒœë¥¼ in_progressë¡œ ë³€ê²½
        await supabase
          .from('celebrities')
          .update({ crawl_status: 'in_progress' })
          .eq('id', celeb.id)

        const title = await searchWikipedia(celeb.name)

        if (!title) {
          await supabase
            .from('celebrities')
            .update({
              crawl_status: 'not_found',
              crawled_at: new Date().toISOString()
            })
            .eq('id', celeb.id)

          results.push({ id: celeb.id, name: celeb.name, success: false, reason: 'ìœ„í‚¤í”¼ë””ì•„ì— ì—†ìŒ' })
          continue
        }

        const crawledData = await getWikipediaPage(title)

        // DB ì—…ë°ì´íŠ¸
        const updateData: Record<string, unknown> = {
          crawl_status: 'completed',
          crawled_at: new Date().toISOString(),
          crawl_source: 'wikipedia'
        }

        // birth_dateê°€ ìˆê³  ê¸°ì¡´ birth_dateê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
        // (ê¸°ì¡´ ë°ì´í„°ë¥¼ ë®ì–´ì“°ì§€ ì•ŠìŒ)

        await supabase
          .from('celebrities')
          .update(updateData)
          .eq('id', celeb.id)

        results.push({
          id: celeb.id,
          name: celeb.name,
          success: true,
          data: {
            description: crawledData.description?.substring(0, 100),
            image_url: crawledData.image_url,
            birth_date: crawledData.birth_date
          }
        })

        console.log(`  âœ… ${celeb.name}: Wikipedia ì¡°íšŒ ì™„ë£Œ`)
      }

      const successCount = results.filter(r => r.success).length

      return new Response(
        JSON.stringify({
          success: true,
          message: `${successCount}/${celebrities.length}ëª… ì¡°íšŒ ì™„ë£Œ`,
          results
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    // ë‹¨ì¼ ëª¨ë“œ
    if (!celebrity_id && !name) {
      return new Response(
        JSON.stringify({ error: 'celebrity_id ë˜ëŠ” name í•„ìš”' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    let targetName = name
    const targetId = celebrity_id

    // celebrity_idë¡œ ì´ë¦„ ì¡°íšŒ
    if (celebrity_id && !name) {
      const { data: celeb, error } = await supabase
        .from('celebrities')
        .select('name')
        .eq('id', celebrity_id)
        .single()

      if (error || !celeb) {
        return new Response(
          JSON.stringify({ error: 'ì—°ì˜ˆì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' }),
          { status: 404, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        )
      }
      targetName = celeb.name
    }

    console.log(`ğŸ” Wikipedia ì¡°íšŒ: ${targetName}`)

    const title = await searchWikipedia(targetName!)

    if (!title) {
      return new Response(
        JSON.stringify({ success: false, error: 'ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' }),
        { status: 404, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      )
    }

    const crawledData = await getWikipediaPage(title)

    // DB ì—…ë°ì´íŠ¸ (celebrity_idê°€ ìˆëŠ” ê²½ìš°)
    if (targetId) {
      await supabase
        .from('celebrities')
        .update({
          crawl_status: 'completed',
          crawled_at: new Date().toISOString(),
          crawl_source: 'wikipedia'
        })
        .eq('id', targetId)
    }

    return new Response(
      JSON.stringify({
        success: true,
        name: targetName,
        wikipedia_title: title,
        data: crawledData
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )

  } catch (error) {
    console.error('âŒ Wikipedia ì¡°íšŒ ì˜¤ë¥˜:', error)
    return new Response(
      JSON.stringify({ error: error instanceof Error ? error.message : 'Unknown error' }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  }
})
