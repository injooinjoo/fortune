/// ê°€ì§œ ë‚˜ë¬´ìœ„í‚¤ ë¤í”„ë¥¼ ë§Œë“¤ê³  ì „ì²´ í”Œë¡œìš°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
/// ì‹¤ì œ ë¤í”„ ì—†ì´ë„ ì „ì²´ ì‹œìŠ¤í…œì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
void main() async {
  print('ğŸ§ª ê°€ì§œ ë¤í”„ ìƒì„± ë° ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘...\n');
  
  // 1. ê°€ì§œ ë¤í”„ ë°ì´í„° ìƒì„±
  await createFakeDumpData();
  
  // 2. ë¤í”„ ì²˜ë¦¬ ë¡œì§ í…ŒìŠ¤íŠ¸  
  await testDumpProcessing();
  
  // 3. ë°ì´í„° ë³€í™˜ ë° ì €ì¥ ì‹œë®¬ë ˆì´ì…˜
  await simulateDataSaveProcess();
  
  print('\nğŸ‰ ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!');
}

/// ê°€ì§œ ë‚˜ë¬´ìœ„í‚¤ ë¤í”„ ë°ì´í„° ìƒì„±
Future<void> createFakeDumpData() async {
  print('ğŸ“ ê°€ì§œ ë¤í”„ ë°ì´í„° ìƒì„± ì¤‘...');
  
  // ì—°ì˜ˆì¸ ëª©ë¡ì—ì„œ ìƒìœ„ 10ëª… ì„ íƒ
  final topCelebrities = [
    {'name': 'ì•„ì´ìœ ', 'category': 'singer'},
    {'name': 'BTS', 'category': 'singer'},
    {'name': 'ì†í¥ë¯¼', 'category': 'sports'},
    {'name': 'ìš°ì™êµ³', 'category': 'streamer'},
    {'name': 'ë°•ì„œì¤€', 'category': 'actor'},
    {'name': 'ì¯”ì–‘', 'category': 'youtuber'},
    {'name': 'ìœ¤ì„ì—´', 'category': 'politician'},
    {'name': 'ì´ì¬ìš©', 'category': 'business'},
    {'name': 'ìœ ì¬ì„', 'category': 'comedian'},
    {'name': 'ê¹€ì—°ê²½', 'category': 'sports'},
  ];
  
  final fakeWikiTexts = <String, String>{};
  
  for (final celebrity in topCelebrities) {
    final name = celebrity['name']!;
    final category = celebrity['category']!;
    
    fakeWikiTexts[name] = generateFakeWikiText(name, category);
  }
  
  print('  âœ… ${fakeWikiTexts.length}ëª…ì˜ ê°€ì§œ ë¤í”„ ë°ì´í„° ìƒì„± ì™„ë£Œ');
  
  // ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥ (ì‹¤ì œë¡œëŠ” íŒŒì¼ë¡œ ì €ì¥)
  _fakeWikiTexts = fakeWikiTexts;
}

/// ê°€ì§œ ìœ„í‚¤í…ìŠ¤íŠ¸ ìƒì„±
String generateFakeWikiText(String name, String category) {
  final birthDate = _generateRandomBirthDate();
  final gender = _getRandomGender();
  final occupation = _getCategoryOccupation(category);
  final debut = _generateRandomDebut();
  final agency = _generateRandomAgency(category);
  
  return '''
{{í‹€:ì¸ë¬¼ ì •ë³´
|ì‚¬ì§„ = ${name}_profile.jpg
|ì´ë¦„ = $name
|ë³¸ëª… = ${name}ì˜ ë³¸ëª…
|ì˜ë¬¸ëª… = ${name.toUpperCase()}
|ìƒë…„ì›”ì¼ = ${birthDate['formatted']}
|ì¶œìƒì§€ = ì„œìš¸íŠ¹ë³„ì‹œ
|êµ­ì  = ëŒ€í•œë¯¼êµ­
|ì§ì—… = $occupation
|í™œë™ì‹œê¸° = $debut ~ í˜„ì¬
|ì¥ë¥´ = ë‹¤ì–‘í•¨
|ì†Œì†ì‚¬ = $agency
|ë°ë·” = $debut
}}

$nameëŠ” ëŒ€í•œë¯¼êµ­ì˜ ${occupation}ì´ë‹¤. ${birthDate['formatted']}ì— íƒœì–´ë‚¬ìœ¼ë©°, 
$debutì— ë°ë·”í•˜ì—¬ í˜„ì¬ê¹Œì§€ í™œë°œí•œ í™œë™ì„ ì´ì–´ê°€ê³  ìˆë‹¤. 
ëŒ€í‘œì ì¸ ì‘í’ˆê³¼ í™œë™ìœ¼ë¡œ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìœ¼ë©°, íŠ¹íˆ ì Šì€ ì¸µì—ê²Œ ì¸ê¸°ê°€ ë†’ë‹¤.
''';
}

Map<String, String> _generateRandomBirthDate() {
  final years = [1985, 1987, 1990, 1992, 1993, 1995, 1998];
  final months = [1, 3, 5, 7, 8, 10, 12];
  final days = [5, 10, 15, 16, 20, 25];
  
  final year = (years..shuffle()).first;
  final month = (months..shuffle()).first;
  final day = (days..shuffle()).first;
  
  return {
    'formatted': '${year}ë…„ ${month}ì›” ${day}ì¼',
    'iso': '$year-${month.toString().padLeft(2, '0')}-${day.toString().padLeft(2, '0')}'
  };
}

String _getRandomGender() {
  return ['male', 'female'][DateTime.now().millisecondsSinceEpoch % 2];
}

String _getCategoryOccupation(String category) {
  switch (category) {
    case 'singer': return 'ê°€ìˆ˜, ìŒì•…ê°€';
    case 'actor': return 'ë°°ìš°, ì—°ê¸°ì';
    case 'sports': return 'ìš´ë™ì„ ìˆ˜';
    case 'streamer': return 'ìŠ¤íŠ¸ë¦¬ë¨¸, BJ';
    case 'youtuber': return 'ìœ íŠœë²„, í¬ë¦¬ì—ì´í„°';
    case 'politician': return 'ì •ì¹˜ì¸';
    case 'business': return 'ê¸°ì—…ì¸, CEO';
    case 'comedian': return 'ì½”ë¯¸ë””ì–¸, ê°œê·¸ë§¨';
    default: return 'ì—°ì˜ˆì¸';
  }
}

String _generateRandomDebut() {
  final years = [2005, 2008, 2010, 2012, 2015, 2018, 2020];
  final year = (years..shuffle()).first;
  return '${year}ë…„';
}

String _generateRandomAgency(String category) {
  final agencies = {
    'singer': ['SMì—”í„°í…Œì¸ë¨¼íŠ¸', 'YGì—”í„°í…Œì¸ë¨¼íŠ¸', 'JYPì—”í„°í…Œì¸ë¨¼íŠ¸', 'EDAMì—”í„°í…Œì¸ë¨¼íŠ¸'],
    'actor': ['ë„·ë§ˆë¸”', 'í‚¹ì½© by ìŠ¤íƒ€ì‹­', 'ë§¤ë‹ˆì§€ë¨¼íŠ¸ ìˆ²', 'BHì—”í„°í…Œì¸ë¨¼íŠ¸'],
    'sports': ['ëŒ€í•œì¶•êµ¬í˜‘íšŒ', 'í”„ë¡œë°°êµ¬ì—°ë§¹', 'í† íŠ¸ë„˜ í™‹ìŠ¤í¼', 'FCì„œìš¸'],
    'streamer': ['ìƒŒë“œë°•ìŠ¤ ë„¤íŠ¸ì›Œí¬', 'DIA TV', 'ì•„í”„ë¦¬ì¹´TV', 'íŠ¸ìœ„ì¹˜'],
    'youtuber': ['ìƒŒë“œë°•ìŠ¤ ë„¤íŠ¸ì›Œí¬', 'CJ ENM', '1ì¸ í¬ë¦¬ì—ì´í„°', 'ë…ë¦½'],
    'politician': ['ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹', 'êµ­ë¯¼ì˜í˜', 'ì •ì˜ë‹¹', 'ë¬´ì†Œì†'],
    'business': ['ì‚¼ì„±', 'LG', 'SK', 'ë„¤ì´ë²„'],
    'comedian': ['SM C&C', 'FNCì—”í„°í…Œì¸ë¨¼íŠ¸', 'YGì¼€ì´í”ŒëŸ¬ìŠ¤', 'ë¬´ì†Œì†'],
  };
  
  final categoryAgencies = agencies[category] ?? ['ì†Œì†ì‚¬ ë¯¸ìƒ'];
  return (categoryAgencies..shuffle()).first;
}

/// ë¤í”„ ì²˜ë¦¬ ë¡œì§ í…ŒìŠ¤íŠ¸
Future<void> testDumpProcessing() async {
  print('\nğŸ”„ ë¤í”„ ì²˜ë¦¬ ë¡œì§ í…ŒìŠ¤íŠ¸ ì¤‘...');
  
  if (_fakeWikiTexts == null || _fakeWikiTexts!.isEmpty) {
    print('  âŒ ê°€ì§œ ë¤í”„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return;
  }
  
  final results = <String, CelebrityInfo>{};
  
  for (final entry in _fakeWikiTexts!.entries) {
    final name = entry.key;
    final wikiText = entry.value;
    
    try {
      final info = parseWikiText(name, wikiText);
      results[name] = info;
      print('  âœ… $name: íŒŒì‹± ì„±ê³µ');
    } catch (e) {
      print('  âŒ $name: íŒŒì‹± ì‹¤íŒ¨ - $e');
    }
  }
  
  print('  ğŸ“Š íŒŒì‹± ê²°ê³¼: ${results.length}/${_fakeWikiTexts!.length} ì„±ê³µ');
  _parsedResults = results;
}

/// ë°ì´í„° ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
Future<void> simulateDataSaveProcess() async {
  print('\nğŸ’¾ ë°ì´í„° ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜...');
  
  if (_parsedResults == null || _parsedResults!.isEmpty) {
    print('  âŒ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
    return;
  }
  
  print('  ğŸ“ celebrities í…Œì´ë¸”ì— ì €ì¥ë  ë°ì´í„°:');
  
  for (final entry in _parsedResults!.entries) {
    final name = entry.key;
    final info = entry.value;
    
    final dbRecord = {
      'name': info.name,
      'birth_date': info.birthDate,
      'birth_time': info.birthTime,
      'gender': info.gender,
      'category': info.category,
      'description': info.description,
      'keywords': info.keywords,
      'additional_info': {
        'debut': info.debut,
        'agency': info.agency,
        'occupation': info.occupation,
        'aliases': info.aliases,
        'processed_from_dump': true,
        'processed_at': DateTime.now().toIso8601String(),
      }
    };
    
    print('    âœ… $name:');
    print('      - ìƒë…„ì›”ì¼: ${info.birthDate ?? 'ì •ë³´ì—†ìŒ'}');
    print('      - ì¹´í…Œê³ ë¦¬: ${info.category}');
    print('      - ë°ë·”: ${info.debut ?? 'ì •ë³´ì—†ìŒ'}');
    print('      - ì†Œì†ì‚¬: ${info.agency ?? 'ì •ë³´ì—†ìŒ'}');
  }
  
  print('  ğŸ¯ ê²°ê³¼: ${_parsedResults!.length}ëª…ì˜ ì—°ì˜ˆì¸ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•  ì¤€ë¹„ ì™„ë£Œ');
}

// ì „ì—­ ë³€ìˆ˜ (ì‹¤ì œë¡œëŠ” í´ë˜ìŠ¤ë‚˜ íŒŒì¼ë¡œ ê´€ë¦¬)
Map<String, String>? _fakeWikiTexts;
Map<String, CelebrityInfo>? _parsedResults;

/// ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì‹± í•¨ìˆ˜ (ì´ì „ í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
CelebrityInfo parseWikiText(String name, String wikiText) {
  return CelebrityInfo(
    name: name,
    birthDate: extractBirthDate(wikiText),
    birthTime: '12:00',
    gender: extractGender(wikiText),
    category: extractCategory(wikiText),
    description: extractDescription(wikiText, name),
    profileImageUrl: extractProfileImage(wikiText),
    keywords: extractKeywords(wikiText, name),
    debut: extractDebut(wikiText),
    agency: extractAgency(wikiText),
    occupation: extractOccupation(wikiText),
    aliases: extractAliases(wikiText, name),
  );
}

// íŒŒì‹± í•¨ìˆ˜ë“¤ (ì´ì „ê³¼ ë™ì¼)
String? extractBirthDate(String wikiText) {
  final patterns = [
    RegExp(r'\|\s*ìƒë…„ì›”ì¼\s*=\s*(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?'),
    RegExp(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*ì¶œìƒ'),
  ];

  for (final pattern in patterns) {
    final match = pattern.firstMatch(wikiText);
    if (match != null && match.groupCount >= 3) {
      final year = match.group(1);
      final month = match.group(2)?.padLeft(2, '0');
      final day = match.group(3)?.padLeft(2, '0');
      
      if (year != null && month != null && day != null) {
        final yearInt = int.tryParse(year);
        if (yearInt != null && yearInt >= 1900 && yearInt <= 2010) {
          return '$year-$month-$day';
        }
      }
    }
  }
  return null;
}

String extractGender(String wikiText) {
  if (wikiText.contains('ì—¬ì„±') || wikiText.contains('ì—¬ë°°ìš°') || wikiText.contains('ì—¬ê°€ìˆ˜')) {
    return 'female';
  }
  return 'male';
}

String extractCategory(String wikiText) {
  if (wikiText.contains('ê°€ìˆ˜') || wikiText.contains('ìŒì•…ê°€')) return 'singer';
  if (wikiText.contains('ë°°ìš°') || wikiText.contains('ì—°ê¸°ì')) return 'actor';
  if (wikiText.contains('ì¶•êµ¬ì„ ìˆ˜') || wikiText.contains('ìš´ë™ì„ ìˆ˜')) return 'sports';
  if (wikiText.contains('ìŠ¤íŠ¸ë¦¬ë¨¸') || wikiText.contains('BJ')) return 'streamer';
  if (wikiText.contains('ìœ íŠœë²„')) return 'youtuber';
  if (wikiText.contains('ì •ì¹˜ì¸')) return 'politician';
  if (wikiText.contains('ê¸°ì—…ì¸') || wikiText.contains('CEO')) return 'business_leader';
  if (wikiText.contains('ì½”ë¯¸ë””ì–¸') || wikiText.contains('ê°œê·¸ë§¨')) return 'entertainer';
  return 'entertainer';
}

String extractDescription(String wikiText, String name) {
  final lines = wikiText.split('\n');
  for (final line in lines) {
    if (line.trim().isNotEmpty && 
        !line.startsWith('|') && 
        !line.startsWith('{{') && 
        line.length > 20) {
      return line.trim().length > 100 ? '${line.trim().substring(0, 100)}...' : line.trim();
    }
  }
  return '$nameì— ëŒ€í•œ ì •ë³´';
}

String? extractProfileImage(String wikiText) {
  final match = RegExp(r'\|\s*ì‚¬ì§„\s*=\s*([^\|\n]+)').firstMatch(wikiText);
  return match?.group(1)?.trim();
}

List<String> extractKeywords(String wikiText, String name) {
  final keywords = <String>{name};
  final terms = ['ë°ë·”', 'í™œë™', 'ì•¨ë²”', 'ë“œë¼ë§ˆ', 'ì˜í™”'];
  for (final term in terms) {
    if (wikiText.contains(term)) keywords.add(term);
  }
  return keywords.toList();
}

String? extractDebut(String wikiText) {
  final match = RegExp(r'\|\s*ë°ë·”\s*=\s*([^\|\n]+)').firstMatch(wikiText);
  return match?.group(1)?.trim();
}

String? extractAgency(String wikiText) {
  final match = RegExp(r'\|\s*ì†Œì†ì‚¬\s*=\s*([^\|\n]+)').firstMatch(wikiText);
  return match?.group(1)?.trim();
}

String? extractOccupation(String wikiText) {
  final match = RegExp(r'\|\s*ì§ì—…\s*=\s*([^\|\n]+)').firstMatch(wikiText);
  return match?.group(1)?.trim();
}

List<String> extractAliases(String wikiText, String name) {
  final aliases = <String>[];
  final match = RegExp(r'\|\s*ë³¸ëª…\s*=\s*([^\|\n]+)').firstMatch(wikiText);
  final realName = match?.group(1)?.trim();
  if (realName != null && realName != name && !realName.contains('ë³¸ëª…')) {
    aliases.add(realName);
  }
  return aliases;
}

// ë°ì´í„° í´ë˜ìŠ¤
class CelebrityInfo {
  final String name;
  final String? birthDate;
  final String? birthTime;
  final String gender;
  final String category;
  final String description;
  final String? profileImageUrl;
  final List<String> keywords;
  final String? debut;
  final String? agency;
  final String? occupation;
  final List<String> aliases;

  CelebrityInfo({
    required this.name,
    this.birthDate,
    this.birthTime,
    required this.gender,
    required this.category,
    required this.description,
    this.profileImageUrl,
    required this.keywords,
    this.debut,
    this.agency,
    this.occupation,
    required this.aliases,
  });
}