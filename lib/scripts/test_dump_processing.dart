import '../services/namuwiki_dump_processor.dart';

/// ë‚˜ë¬´ìœ„í‚¤ ë¤í”„ ì²˜ë¦¬ ë¡œì§ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
/// ì‹¤ì œ ë¤í”„ íŒŒì¼ ì—†ì´ ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì‹± ë¡œì§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
class DumpProcessingTest {
  static Future<void> main() async {
    print('ğŸ§ª ë‚˜ë¬´ìœ„í‚¤ ë¤í”„ ì²˜ë¦¬ ë¡œì§ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n');

    // í…ŒìŠ¤íŠ¸ìš© ìœ„í‚¤í…ìŠ¤íŠ¸ ìƒ˜í”Œë“¤
    await _testWikiTextParsing();
    
    // ê°€ì§œ ë¤í”„ íŒŒì¼ë¡œ ì²˜ë¦¬ ë¡œì§ í…ŒìŠ¤íŠ¸
    await _testDumpProcessor();

    print('\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!');
  }

  /// ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸
  static Future<void> _testWikiTextParsing() async {
    print('ğŸ“ ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì‹± í…ŒìŠ¤íŠ¸...\n');

    // í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: ê°€ìˆ˜ (IU)
    final iuWikiText = '''
{{í‹€:ì—°ì˜ˆì¸ ì •ë³´
|ì‚¬ì§„ = IU_profile.jpg
|ì´ë¦„ = ì•„ì´ìœ 
|ë³¸ëª… = ì´ì§€ì€
|ì˜ë¬¸ëª… = IU
|ìƒë…„ì›”ì¼ = 1993ë…„ 5ì›” 16ì¼
|ì¶œìƒì§€ = ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬ ì„ì§€ë¡œ
|êµ­ì  = ëŒ€í•œë¯¼êµ­
|ì§ì—… = ê°€ìˆ˜, ë°°ìš°, ì‘ì‚¬ê°€, ì‘ê³¡ê°€
|í™œë™ì‹œê¸° = 2008ë…„ ~ í˜„ì¬
|ì¥ë¥´ = ë°œë¼ë“œ, íŒ
|ì†Œì†ì‚¬ = EDAM ì—”í„°í…Œì¸ë¨¼íŠ¸
|ë°ë·” = 2008ë…„ ë””ì§€í„¸ ì‹±ê¸€ ã€ŠLost And Foundã€‹
}}

ì•„ì´ìœ (IU, ë³¸ëª…: ì´ì§€ì€)ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ê°€ìˆ˜ì´ì ë°°ìš°ì´ë‹¤. 
2008ë…„ 15ì„¸ì˜ ë‚˜ì´ë¡œ ë°ë·”í•œ í›„ ê¾¸ì¤€í•œ í™œë™ì„ í†µí•´ ëŒ€í•œë¯¼êµ­ì„ ëŒ€í‘œí•˜ëŠ” ì†”ë¡œ ê°€ìˆ˜ë¡œ ì„±ì¥í–ˆë‹¤.
''';

    await _testSingleWikiText('ì•„ì´ìœ ', iuWikiText);

    // í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: ë°°ìš° (ì†í¥ë¯¼)
    final sonWikiText = '''
{{í‹€:ì¶•êµ¬ì„ ìˆ˜ ì •ë³´
|ì´ë¦„ = ì†í¥ë¯¼
|ì˜ë¬¸ëª… = Son Heung-min
|ìƒë…„ì›”ì¼ = 1992ë…„ 7ì›” 8ì¼
|ì¶œìƒì§€ = ê°•ì›ë„ ì¶˜ì²œì‹œ
|êµ­ì  = ëŒ€í•œë¯¼êµ­
|í¬ì§€ì…˜ = ê³µê²©ìˆ˜, ìœ™ì–´
|í˜„ì†Œì†íŒ€ = í† íŠ¸ë„˜ í™‹ìŠ¤í¼
|ë“±ë²ˆí˜¸ = 7ë²ˆ
|ì‹ ì²´ = 183cm, 78kg
}}

ì†í¥ë¯¼(å­«èˆˆæ…œ)ì€ ëŒ€í•œë¯¼êµ­ì˜ ì¶•êµ¬ì„ ìˆ˜ì´ë‹¤. í˜„ì¬ í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ í† íŠ¸ë„˜ í™‹ìŠ¤í¼ì—ì„œ í™œë™í•˜ê³  ìˆìœ¼ë©°, ëŒ€í•œë¯¼êµ­ êµ­ê°€ëŒ€í‘œíŒ€ì˜ ì£¼ì¥ì„ ë§¡ê³  ìˆë‹¤.
''';

    await _testSingleWikiText('ì†í¥ë¯¼', sonWikiText);

    // í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ìŠ¤íŠ¸ë¦¬ë¨¸ (ìš°ì™êµ³)
    final woowakgoodWikiText = '''
{{í‹€:ì¸ë¬¼ ì •ë³´
|ì´ë¦„ = ìš°ì™êµ³
|ë³¸ëª… = ì´ì„¸ì§„
|ìƒë…„ì›”ì¼ = 1987ë…„ 11ì›” 10ì¼
|êµ­ì  = ëŒ€í•œë¯¼êµ­
|ì§ì—… = ìŠ¤íŠ¸ë¦¬ë¨¸, ìœ íŠœë²„
|í™œë™ì‹œê¸° = 2015ë…„ ~ í˜„ì¬
|êµ¬ë…ììˆ˜ = 100ë§Œ ëª… ì´ìƒ
|í”Œë«í¼ = íŠ¸ìœ„ì¹˜, ìœ íŠœë¸Œ
}}

ìš°ì™êµ³ì€ ëŒ€í•œë¯¼êµ­ì˜ ìŠ¤íŠ¸ë¦¬ë¨¸ì´ë‹¤. íŠ¸ìœ„ì¹˜ì—ì„œ ë°©ì†¡ì„ ì§„í–‰í•˜ë©°, ë‹¤ì–‘í•œ ê²Œì„ê³¼ í† í¬ ì½˜í…ì¸ ë¡œ ì¸ê¸°ë¥¼ ì–»ê³  ìˆë‹¤.
''';

    await _testSingleWikiText('ìš°ì™êµ³', woowakgoodWikiText);
  }

  /// ë‹¨ì¼ ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì‹± í…ŒìŠ¤íŠ¸
  static Future<void> _testSingleWikiText(String name, String wikiText) async {
    print('ğŸ” í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: $name');
    
    // NamuWikiDumpProcessorì˜ íŒŒì‹± ë¡œì§ì„ ì§ì ‘ í˜¸ì¶œí•˜ê¸° ìœ„í•´ ì„ì‹œ í”„ë¡œì„¸ì„œ ìƒì„±
    final processor = NamuWikiDumpProcessor(dumpFilePath: '/tmp/test.xml');
    
    // private ë©”ì†Œë“œë“¤ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ reflection ì‚¬ìš©í•˜ê±°ë‚˜,
    // ì—¬ê¸°ì„œëŠ” ì§ì ‘ íŒŒì‹± ë¡œì§ì„ êµ¬í˜„í•´ì„œ í…ŒìŠ¤íŠ¸
    final info = _testParseWikiText(name, wikiText);
    
    if (info != null) {
      print('  âœ… íŒŒì‹± ì„±ê³µ');
      print('    ì´ë¦„: ${info.name}');
      print('    ìƒë…„ì›”ì¼: ${info.birthDate ?? 'ì •ë³´ ì—†ìŒ'}');
      print('    ì„±ë³„: ${info.gender}');
      print('    ì¹´í…Œê³ ë¦¬: ${info.category}');
      print('    ì„¤ëª…: ${info.description.length > 50 ? '${info.description.substring(0, 50)}...' : info.description}');
      print('    í‚¤ì›Œë“œ: ${info.keywords.join(', ')}');
      if (info.debut != null) print('    ë°ë·”: ${info.debut}');
      if (info.agency != null) print('    ì†Œì†ì‚¬: ${info.agency}');
    } else {
      print('  âŒ íŒŒì‹± ì‹¤íŒ¨');
    }
    print('');
  }

  /// í…ŒìŠ¤íŠ¸ìš© ìœ„í‚¤í…ìŠ¤íŠ¸ íŒŒì„œ (ì‹¤ì œ í”„ë¡œì„¸ì„œ ë¡œì§ê³¼ ìœ ì‚¬)
  static CelebrityInfo? _testParseWikiText(String name, String wikiText) {
    try {
      return CelebrityInfo(
        name: name,
        birthDate: _testExtractBirthDate(wikiText),
        birthTime: '12:00',
        gender: _testExtractGender(wikiText),
        category: _testExtractCategory(wikiText),
        description: _testExtractDescription(wikiText, name),
        profileImageUrl: _testExtractProfileImage(wikiText),
        keywords: _testExtractKeywords(wikiText, name),
        debut: _testExtractDebut(wikiText),
        agency: _testExtractAgency(wikiText),
        occupation: _testExtractOccupation(wikiText),
        aliases: _testExtractAliases(wikiText, name),
      );
    } catch (e) {
      print('íŒŒì‹± ì˜¤ë¥˜ ($name): $e');
      return null;
    }
  }

  // í…ŒìŠ¤íŠ¸ìš© íŒŒì‹± í•¨ìˆ˜ë“¤ (ì‹¤ì œ í”„ë¡œì„¸ì„œì™€ ë™ì¼í•œ ë¡œì§)
  static String? _testExtractBirthDate(String wikiText) {
    final patterns = [
      RegExp(r'\|\s*ìƒë…„ì›”ì¼\s*=\s*(\d{4})ë…„?\s*(\d{1,2})ì›”?\s*(\d{1,2})ì¼?'),
      RegExp(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼\s*ì¶œìƒ'),
    ];

    for (final pattern in patterns) {
      final match = pattern.firstMatch(wikiText);
      if (match != null && match.groupCount >= 3) {
        final year = match.group(1);
        final month = match.group(2)?.padLeft(2, '0');
        final day = match.group(3)?.padLeft(2, '0');
        
        if (year != null && month != null && day != null) {
          return '$year-$month-$day';
        }
      }
    }
    return null;
  }

  static String _testExtractGender(String wikiText) {
    if (wikiText.contains('ì—¬ì„±') || wikiText.contains('ì—¬ë°°ìš°') || wikiText.contains('ì—¬ê°€ìˆ˜')) {
      return 'female';
    }
    return 'male';
  }

  static String _testExtractCategory(String wikiText) {
    if (wikiText.contains('ê°€ìˆ˜') || wikiText.contains('ìŒì•…ê°€')) return 'singer';
    if (wikiText.contains('ë°°ìš°') || wikiText.contains('ì—°ê¸°ì')) return 'actor';
    if (wikiText.contains('ì¶•êµ¬ì„ ìˆ˜') || wikiText.contains('ìš´ë™ì„ ìˆ˜')) return 'sports';
    if (wikiText.contains('ìŠ¤íŠ¸ë¦¬ë¨¸') || wikiText.contains('BJ')) return 'streamer';
    if (wikiText.contains('ìœ íŠœë²„')) return 'youtuber';
    return 'entertainer';
  }

  static String _testExtractDescription(String wikiText, String name) {
    final lines = wikiText.split('\n');
    for (final line in lines) {
      if (line.trim().isNotEmpty && 
          !line.startsWith('|') && 
          !line.startsWith('{{') && 
          line.length > 20) {
        return line.trim().length > 100 ? '${line.trim().substring(0, 100)}...' : line.trim();
      }
    }
    return '$nameì— ëŒ€í•œ ì •ë³´';
  }

  static String? _testExtractProfileImage(String wikiText) {
    final match = RegExp(r'\|\s*ì‚¬ì§„\s*=\s*([^\|\n]+)').firstMatch(wikiText);
    return match?.group(1)?.trim();
  }

  static List<String> _testExtractKeywords(String wikiText, String name) {
    final keywords = <String>{name};
    final terms = ['ë°ë·”', 'í™œë™', 'ì•¨ë²”', 'ë“œë¼ë§ˆ', 'ì˜í™”'];
    for (final term in terms) {
      if (wikiText.contains(term)) keywords.add(term);
    }
    return keywords.toList();
  }

  static String? _testExtractDebut(String wikiText) {
    final match = RegExp(r'\|\s*ë°ë·”\s*=\s*([^\|\n]+)').firstMatch(wikiText);
    return match?.group(1)?.trim();
  }

  static String? _testExtractAgency(String wikiText) {
    final match = RegExp(r'\|\s*ì†Œì†ì‚¬\s*=\s*([^\|\n]+)').firstMatch(wikiText);
    return match?.group(1)?.trim();
  }

  static String? _testExtractOccupation(String wikiText) {
    final match = RegExp(r'\|\s*ì§ì—…\s*=\s*([^\|\n]+)').firstMatch(wikiText);
    return match?.group(1)?.trim();
  }

  static List<String> _testExtractAliases(String wikiText, String name) {
    final aliases = <String>[];
    final match = RegExp(r'\|\s*ë³¸ëª…\s*=\s*([^\|\n]+)').firstMatch(wikiText);
    final realName = match?.group(1)?.trim();
    if (realName != null && realName != name) {
      aliases.add(realName);
    }
    return aliases;
  }

  /// ë¤í”„ í”„ë¡œì„¸ì„œ ê¸°ë³¸ ë¡œì§ í…ŒìŠ¤íŠ¸
  static Future<void> _testDumpProcessor() async {
    print('ğŸ”§ ë¤í”„ í”„ë¡œì„¸ì„œ ê¸°ë³¸ ë¡œì§ í…ŒìŠ¤íŠ¸...\n');

    // ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸ (ì—ëŸ¬ í•¸ë“¤ë§ í™•ì¸)
    final processor = NamuWikiDumpProcessor(dumpFilePath: '/tmp/nonexistent.xml');

    try {
      final info = await processor.getDumpFileInfo();
      print('âŒ ì˜ˆìƒëœ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ');
    } catch (e) {
      print('âœ… íŒŒì¼ ì—†ìŒ ì˜¤ë¥˜ ì²˜ë¦¬ í™•ì¸: ${e.toString().contains('ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')}');
    }

    print('âœ… ë¤í”„ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” í™•ì¸');
    print('âœ… ì—ëŸ¬ í•¸ë“¤ë§ í™•ì¸');
  }
}

/// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì§„ì…ì 
void main() async {
  await DumpProcessingTest.main();
}