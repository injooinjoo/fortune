import 'dart:async';
import 'package:supabase_flutter/supabase_flutter.dart';
import '../data/models/celebrity_master_list.dart';
import '../data/models/celebrity.dart';
import 'celebrity_list_service.dart';
import 'celebrity_crawling_service.dart';

/// ë‚˜ë¬´ìœ„í‚¤ í¬ë¡¤ë§ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ì„œë¹„ìŠ¤
/// celebrity_master_listì—ì„œ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì—°ì˜ˆì¸ì„ ì„ íƒí•˜ê³ 
/// í¬ë¡¤ë§ í›„ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
class CelebrityCrawlingOrchestrator {
  final SupabaseClient _supabase = Supabase.instance.client;
  final CelebrityListService _listService = CelebrityListService();
  final CelebrityCrawlingService _crawlingService = CelebrityCrawlingService();

  /// ë‹¤ìŒ í¬ë¡¤ë§ ëŒ€ìƒ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
  Future<List<CelebrityMasterListItem>> getNextBatchToCrawl({
    int batchSize = 10,
    String? category,
  }) async {
    try {
      return await _listService.getNextCelebritiesToCrawl(
        limit: batchSize,
        category: category,
      );
    } catch (e) {
      throw Exception('ë‹¤ìŒ í¬ë¡¤ë§ ëŒ€ìƒ ì¡°íšŒ ì‹¤íŒ¨: $e');
    }
  }

  /// ë‹¨ì¼ ì—°ì˜ˆì¸ í¬ë¡¤ë§ ë° ì €ì¥
  Future<CrawlingOperationResult> crawlAndSaveSingle(
    CelebrityMasterListItem masterItem,
  ) async {
    try {
      print('ğŸ”„ í¬ë¡¤ë§ ì‹œì‘: ${masterItem.name} (${masterItem.category.displayName})');

      // 1. ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ì •ë³´ í¬ë¡¤ë§ (masterItemId í¬í•¨)
      final crawlingResult = await _crawlingService.crawlCelebrityInfo(
        name: masterItem.name,
        forceUpdate: true,
        masterItemId: masterItem.id,
      );

      if (!crawlingResult.success) {
        return CrawlingOperationResult(
          masterItem: masterItem,
          success: false,
          error: crawlingResult.message,
          celebrity: null,
        );
      }

      // 2. í¬ë¡¤ë§ ì„±ê³µ ì‹œ ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
      await _listService.markCelebrityAsCrawled(masterItem.id);

      print('âœ… í¬ë¡¤ë§ ì™„ë£Œ: ${masterItem.name}');

      return CrawlingOperationResult(
        masterItem: masterItem,
        success: true,
        error: null,
        celebrity: crawlingResult.celebrity,
      );

    } catch (e) {
      print('âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: ${masterItem.name} - $e');
      
      return CrawlingOperationResult(
        masterItem: masterItem,
        success: false,
        error: e.toString(),
        celebrity: null,
      );
    }
  }

  /// ë°°ì¹˜ í¬ë¡¤ë§ ì‹¤í–‰
  Future<BatchCrawlingOperationResult> crawlBatch({
    int batchSize = 10,
    String? category,
    Duration delayBetweenCrawls = const Duration(seconds: 1),
    Function(CrawlingOperationResult result)? onItemComplete,
    Function(int current, int total)? onProgress,
  }) async {
    try {
      // 1. ë‹¤ìŒ í¬ë¡¤ë§ ëŒ€ìƒë“¤ ê°€ì ¸ì˜¤ê¸°
      final targetItems = await getNextBatchToCrawl(
        batchSize: batchSize,
        category: category,
      );

      if (targetItems.isEmpty) {
        return BatchCrawlingOperationResult(
          results: [],
          totalCount: 0,
          successCount: 0,
          failureCount: 0,
          skippedCount: 0,
        );
      }

      print('ğŸ“‹ ë°°ì¹˜ í¬ë¡¤ë§ ì‹œì‘: ${targetItems.length}ëª…');

      final results = <CrawlingOperationResult>[];
      int successCount = 0;
      int failureCount = 0;

      // 2. ê° ì—°ì˜ˆì¸ì— ëŒ€í•´ ìˆœì°¨ í¬ë¡¤ë§
      for (int i = 0; i < targetItems.length; i++) {
        final item = targetItems[i];
        
        // ì§„í–‰ ìƒí™© ì•Œë¦¼
        onProgress?.call(i + 1, targetItems.length);

        // í¬ë¡¤ë§ ì‹¤í–‰
        final result = await crawlAndSaveSingle(item);
        results.add(result);

        if (result.success) {
          successCount++;
        } else {
          failureCount++;
        }

        // ì™„ë£Œ ì½œë°± í˜¸ì¶œ
        onItemComplete?.call(result);

        // ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
        if (i < targetItems.length - 1) {
          await Future.delayed(delayBetweenCrawls);
        }
      }

      print('ğŸ“Š ë°°ì¹˜ í¬ë¡¤ë§ ì™„ë£Œ - ì„±ê³µ: $successCount, ì‹¤íŒ¨: $failureCount');

      return BatchCrawlingOperationResult(
        results: results,
        totalCount: targetItems.length,
        successCount: successCount,
        failureCount: failureCount,
        skippedCount: 0,
      );

    } catch (e) {
      throw Exception('ë°°ì¹˜ í¬ë¡¤ë§ ì‹¤íŒ¨: $e');
    }
  }

  /// ì „ì²´ í¬ë¡¤ë§ ìƒíƒœ í™•ì¸
  Future<OverallCrawlingStatus> getOverallStatus() async {
    try {
      // ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ í†µê³„
      final masterStats = await _listService.getCrawlingStats();
      
      // ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
      final categoryStats = await _listService.getCategoryStats();

      // ì‹¤ì œ ì €ì¥ëœ celebrities í†µê³„
      final celebritiesStats = await _crawlingService.getCrawlingStats();

      return OverallCrawlingStatus(
        totalCelebrities: masterStats.totalCelebrities,
        crawledCelebrities: masterStats.crawledCelebrities,
        crawlingPercentage: masterStats.crawlingPercentage,
        lastCrawledAt: masterStats.lastCrawledAt,
        categoryStats: categoryStats,
        actualStoredCount: celebritiesStats.crawledCelebrities,
      );

    } catch (e) {
      throw Exception('ì „ì²´ í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: $e');
    }
  }

  /// ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§ ì‹¤í–‰
  Future<BatchCrawlingOperationResult> crawlByCategory(
    String categoryCode, {
    int batchSize = 10,
    Duration delayBetweenCrawls = const Duration(seconds: 1),
    Function(CrawlingOperationResult result)? onItemComplete,
    Function(int current, int total)? onProgress,
  }) async {
    return await crawlBatch(
      batchSize: batchSize,
      category: categoryCode,
      delayBetweenCrawls: delayBetweenCrawls,
      onItemComplete: onItemComplete,
      onProgress: onProgress,
    );
  }

  /// ì‹¤íŒ¨í•œ í¬ë¡¤ë§ ì¬ì‹œë„
  Future<BatchCrawlingOperationResult> retryFailedCrawls({
    int batchSize = 5,
    Duration delayBetweenCrawls = const Duration(seconds: 2),
  }) async {
    try {
      // is_crawled = falseì¸ ì•„ì´í…œë“¤ ì¤‘ì—ì„œ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒë“¤ì„ ì¬ì‹œë„ ëŒ€ìƒìœ¼ë¡œ ì„ íƒ
      final failedItems = await _listService.getNextCelebritiesToCrawl(
        limit: batchSize,
      );

      if (failedItems.isEmpty) {
        return BatchCrawlingOperationResult(
          results: [],
          totalCount: 0,
          successCount: 0,
          failureCount: 0,
          skippedCount: 0,
        );
      }

      print('ğŸ”„ ì‹¤íŒ¨í•œ í¬ë¡¤ë§ ì¬ì‹œë„: ${failedItems.length}ëª…');

      return await crawlBatch(
        batchSize: batchSize,
        delayBetweenCrawls: delayBetweenCrawls,
        onItemComplete: (result) {
          if (result.success) {
            print('âœ… ì¬ì‹œë„ ì„±ê³µ: ${result.masterItem.name}');
          } else {
            print('âŒ ì¬ì‹œë„ ì‹¤íŒ¨: ${result.masterItem.name} - ${result.error}');
          }
        },
      );

    } catch (e) {
      throw Exception('ì‹¤íŒ¨í•œ í¬ë¡¤ë§ ì¬ì‹œë„ ì‹¤íŒ¨: $e');
    }
  }

  /// íŠ¹ì • ì—°ì˜ˆì¸ ê°•ì œ ì¬í¬ë¡¤ë§
  Future<CrawlingOperationResult> forceCrawl(String celebrityName) async {
    try {
      // ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì—°ì˜ˆì¸ ì°¾ê¸°
      final allCelebrities = await _supabase
          .from('celebrity_master_list')
          .select('*')
          .eq('name', celebrityName)
          .limit(1);

      if (allCelebrities.isEmpty) {
        throw Exception('í•´ë‹¹ ì—°ì˜ˆì¸ì„ ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $celebrityName');
      }

      final masterItem = CelebrityMasterListItem.fromJson(allCelebrities.first);

      // í¬ë¡¤ë§ ì‹¤í–‰ (ê¸°ì¡´ ìƒíƒœì™€ ê´€ê³„ì—†ì´ ê°•ì œ ì‹¤í–‰)
      return await crawlAndSaveSingle(masterItem);

    } catch (e) {
      throw Exception('ê°•ì œ í¬ë¡¤ë§ ì‹¤íŒ¨: $e');
    }
  }
}

/// ê°œë³„ í¬ë¡¤ë§ ì‘ì—… ê²°ê³¼
class CrawlingOperationResult {
  final CelebrityMasterListItem masterItem;
  final bool success;
  final String? error;
  final Celebrity? celebrity;

  CrawlingOperationResult({
    required this.masterItem,
    required this.success,
    this.error,
    this.celebrity,
  });
}

/// ë°°ì¹˜ í¬ë¡¤ë§ ì‘ì—… ê²°ê³¼
class BatchCrawlingOperationResult {
  final List<CrawlingOperationResult> results;
  final int totalCount;
  final int successCount;
  final int failureCount;
  final int skippedCount;

  BatchCrawlingOperationResult({
    required this.results,
    required this.totalCount,
    required this.successCount,
    required this.failureCount,
    required this.skippedCount,
  });

  double get successRate => totalCount > 0 ? (successCount / totalCount) * 100 : 0;

  List<CrawlingOperationResult> get successfulResults =>
      results.where((r) => r.success).toList();

  List<CrawlingOperationResult> get failedResults =>
      results.where((r) => !r.success).toList();
}

/// ì „ì²´ í¬ë¡¤ë§ ìƒíƒœ
class OverallCrawlingStatus {
  final int totalCelebrities;
  final int crawledCelebrities;
  final double crawlingPercentage;
  final DateTime? lastCrawledAt;
  final Map<String, CategoryStats> categoryStats;
  final int actualStoredCount;

  OverallCrawlingStatus({
    required this.totalCelebrities,
    required this.crawledCelebrities,
    required this.crawlingPercentage,
    this.lastCrawledAt,
    required this.categoryStats,
    required this.actualStoredCount,
  });

  int get remainingCount => totalCelebrities - crawledCelebrities;
  
  bool get isComplete => crawledCelebrities >= totalCelebrities;

  /// ë°ì´í„° ì¼ê´€ì„± í™•ì¸ (ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ vs ì‹¤ì œ ì €ì¥ëœ ë°ì´í„°)
  bool get isDataConsistent => crawledCelebrities == actualStoredCount;
}