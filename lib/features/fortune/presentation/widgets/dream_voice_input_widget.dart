import 'package:flutter/material.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import '../../../../core/design_system/design_system.dart';
import '../../../../core/utils/haptic_utils.dart';
import '../../../../services/speech_recognition_service.dart';
import '../providers/dream_voice_provider.dart';
import 'voice_spectrum_animation.dart';

/// í•˜ë‹¨ ìŒì„± ì…ë ¥ ì˜ì—­ (ChatGPT ìŠ¤íƒ€ì¼)
///
/// ë ˆì´ì•„ì›ƒ: [ê¸´ íƒ€ì›í˜• (TextField + ë§ˆì´í¬)] [ê²€ì • ë™ê·¸ë¼ë¯¸ ë²„íŠ¼]
class DreamVoiceInputWidget extends ConsumerStatefulWidget {
  final Function(String) onTextRecognized;

  const DreamVoiceInputWidget({
    super.key,
    required this.onTextRecognized,
  });

  @override
  ConsumerState<DreamVoiceInputWidget> createState() => _DreamVoiceInputWidgetState();
}

class _DreamVoiceInputWidgetState extends ConsumerState<DreamVoiceInputWidget> {
  final _textController = TextEditingController();
  final _speechService = SpeechRecognitionService();
  bool _isRecording = false;
  bool _hasText = false;
  bool _isSpeaking = false; // ì‹¤ì œ ìŒì„± ì¸ì‹ ì¤‘ì¸ì§€

  @override
  void initState() {
    super.initState();
    // ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ ì‹œ ê¶Œí•œ í™•ì¸í•˜ë¯€ë¡œ initStateì—ì„œëŠ” ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ

    // í…ìŠ¤íŠ¸ ë³€í™” ê°ì§€
    _textController.addListener(_onTextChanged);

    // ì„œë¹„ìŠ¤ ìƒíƒœ ë³€í™” ê°ì§€ (UI ë™ê¸°í™”)
    _speechService.isListeningNotifier.addListener(_onListeningStateChanged);
  }

  void _onTextChanged() {
    final newHasText = _textController.text.isNotEmpty;
    if (_hasText != newHasText) {
      setState(() {
        _hasText = newHasText;
      });
    }
  }

  /// ì„œë¹„ìŠ¤ ìƒíƒœê°€ ë³€ê²½ë˜ë©´ UI ë™ê¸°í™”
  void _onListeningStateChanged() {
    if (!_speechService.isListeningNotifier.value && mounted) {
      // ì„œë¹„ìŠ¤ê°€ ì¤‘ì§€ë˜ì—ˆëŠ”ë° UIê°€ ì•„ì§ recording ìƒíƒœë©´ ë³µêµ¬
      if (_isRecording) {
        final text = _textController.text.trim();
        // í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ hasText ìœ ì§€, ì—†ìœ¼ë©´ idleë¡œ
        if (text.isNotEmpty) {
          setState(() {
            _isRecording = false;
            _hasText = true;
          });
        }
        // í…ìŠ¤íŠ¸ ì—†ìœ¼ë©´ ìë™ ì¬ì‹œì‘ì´ ì²˜ë¦¬í•¨
      }
    }
  }

  @override
  void dispose() {
    _textController.removeListener(_onTextChanged);
    _speechService.isListeningNotifier.removeListener(_onListeningStateChanged);
    _textController.dispose();
    _speechService.dispose();
    super.dispose();
  }

  /// ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ - ë…¹ìŒ ì‹œì‘
  Future<void> _startRecording() async {
    HapticUtils.lightImpact();

    // 1. ê¶Œí•œ ìƒíƒœ í™•ì¸
    final permissionStatus = await _speechService.checkPermissionStatus();

    if (permissionStatus != MicrophonePermissionStatus.granted) {
      // ê¶Œí•œì´ ì—†ìœ¼ë©´ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
      if (!mounted) return;
      await _showPermissionDialog(permissionStatus);
      return;
    }

    // 2. ê¶Œí•œì´ ìˆìœ¼ë©´ ë…¹ìŒ ì‹œì‘
    setState(() {
      _isRecording = true;
      _isSpeaking = false;
      _textController.clear();
    });

    // Provider ìƒíƒœ ì—…ë°ì´íŠ¸
    ref.read(dreamVoiceProvider.notifier).startRecording();

    await _startListeningWithAutoRestart();
  }

  /// ìë™ ì¬ì‹œì‘ ì§€ì›í•˜ëŠ” ìŒì„± ì¸ì‹ ì‹œì‘
  Future<void> _startListeningWithAutoRestart() async {
    await _speechService.startListening(
      onResult: (text) {
        // Final result - ë…¹ìŒ ì™„ë£Œ
        if (text.isNotEmpty && mounted) {
          setState(() => _isSpeaking = false);
          _textController.text = text;
          _textController.selection = TextSelection.fromPosition(
            TextPosition(offset: text.length),
          );
        }
      },
      onPartialResult: (text) {
        // Partial result - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        if (text.isNotEmpty && mounted) {
          setState(() => _isSpeaking = true); // ë§í•˜ëŠ” ì¤‘!
          _textController.text = text;
          _textController.selection = TextSelection.fromPosition(
            TextPosition(offset: text.length),
          );

          ref.read(dreamVoiceProvider.notifier).updateRecognizedText(text);
        }
      },
      onNoMatch: () {
        // error_no_match ë°œìƒ ì‹œ ìë™ ì¬ì‹œì‘
        if (mounted && _isRecording) {
          debugPrint('ğŸ¤ [DreamVoice] Auto-restarting after no_match');
          _startListeningWithAutoRestart();
        } else {
          // stop ë²„íŠ¼ ëˆŒë €ê±°ë‚˜ mounted ì•„ë‹ˆë©´ idleë¡œ ë³µêµ¬
          if (mounted) {
            setState(() => _isRecording = false);
            ref.read(dreamVoiceProvider.notifier).stopRecording();
          }
        }
      },
    );
  }

  /// ê¶Œí•œ ìš”ì²­ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
  Future<void> _showPermissionDialog(MicrophonePermissionStatus status) async {
    final isDark = Theme.of(context).brightness == Brightness.dark;

    await showDialog<void>(
      context: context,
      builder: (context) => AlertDialog(
        backgroundColor: isDark ? Colors.grey[900] : Colors.white,
        shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(16)),
        title: Row(
          children: [
            Icon(Icons.mic, color: isDark ? Colors.white : Colors.black),
            const SizedBox(width: 8),
            Text(
              'ë§ˆì´í¬ ê¶Œí•œ í•„ìš”',
              style: TextStyle(
                color: isDark ? Colors.white : Colors.black,
                fontWeight: FontWeight.w600,
              ),
            ),
          ],
        ),
        content: Text(
          'ìŒì„±ìœ¼ë¡œ ê¿ˆì„ ì…ë ¥í•˜ë ¤ë©´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          style: TextStyle(
            color: isDark ? Colors.grey[300] : Colors.grey[700],
          ),
        ),
        actions: [
          TextButton(
            onPressed: () => Navigator.pop(context),
            child: Text(
              'ì·¨ì†Œ',
              style: TextStyle(
                color: isDark ? Colors.grey[400] : Colors.grey[600],
              ),
            ),
          ),
          ElevatedButton(
            onPressed: () async {
              Navigator.pop(context);

              if (status == MicrophonePermissionStatus.permanentlyDenied) {
                // ì„¤ì •ìœ¼ë¡œ ì´ë™
                await _speechService.openSettings();
              } else {
                // ê¶Œí•œ ìš”ì²­
                final result = await _speechService.requestPermission();
                if (result == MicrophonePermissionStatus.granted) {
                  // ê¶Œí•œ íšë“ ì„±ê³µ - ë…¹ìŒ ì‹œì‘
                  _startRecording();
                } else if (result == MicrophonePermissionStatus.permanentlyDenied) {
                  // ì˜êµ¬ ê±°ë¶€ë¨ - ì„¤ì •ìœ¼ë¡œ ì•ˆë‚´
                  if (mounted) {
                    ScaffoldMessenger.of(context).showSnackBar(
                      SnackBar(
                        content: const Text('ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”'),
                        action: SnackBarAction(
                          label: 'ì„¤ì • ì—´ê¸°',
                          onPressed: () => _speechService.openSettings(),
                        ),
                      ),
                    );
                  }
                }
              }
            },
            style: ElevatedButton.styleFrom(
              backgroundColor: isDark ? Colors.white : Colors.black,
              foregroundColor: isDark ? Colors.black : Colors.white,
              shape: RoundedRectangleBorder(
                borderRadius: BorderRadius.circular(8),
              ),
            ),
            child: Text(
              status == MicrophonePermissionStatus.permanentlyDenied
                  ? 'ì„¤ì •ìœ¼ë¡œ ì´ë™'
                  : 'ê¶Œí•œ í—ˆìš©í•˜ê¸°',
            ),
          ),
        ],
      ),
    );
  }

  /// ì •ì§€ ë²„íŠ¼ í´ë¦­ - ë…¹ìŒ ì¤‘ì§€ ë° ì „ì†¡
  Future<void> _stopRecordingAndSend() async {
    HapticUtils.lightImpact();

    // ë…¹ìŒ ì¤‘ì§€
    await _speechService.stopListening();

    // Provider ìƒíƒœ ì—…ë°ì´íŠ¸
    ref.read(dreamVoiceProvider.notifier).stopRecording();

    // STT ë³€í™˜ ëŒ€ê¸° (ì¢€ ë” ê¸´ ë”œë ˆì´)
    await Future.delayed(const Duration(milliseconds: 500));

    // í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì „ì†¡
    final text = _textController.text.trim();
    if (text.isNotEmpty) {
      widget.onTextRecognized(text);

      // ì…ë ¥ë€ ì´ˆê¸°í™”
      setState(() {
        _textController.clear();
        _hasText = false;
        _isRecording = false;
      });
    } else {
      // í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë…¹ìŒ ì¤‘ì§€ë§Œ
      setState(() {
        _isRecording = false;
      });
    }
  }

  /// ì „ì†¡ ë²„íŠ¼ í´ë¦­ - í…ìŠ¤íŠ¸ ì „ì†¡
  void _sendText() {
    HapticUtils.lightImpact();

    final text = _textController.text.trim();
    if (text.isNotEmpty) {
      widget.onTextRecognized(text);

      // ì…ë ¥ë€ ì´ˆê¸°í™”
      setState(() {
        _textController.clear();
        _hasText = false;
      });
    }
  }

  @override
  Widget build(BuildContext context) {
    final isDark = Theme.of(context).brightness == Brightness.dark;
    final keyboardHeight = MediaQuery.of(context).viewInsets.bottom;
    final bottomSafeArea = MediaQuery.of(context).padding.bottom;

    // ë²„íŠ¼ í‘œì‹œ ì—¬ë¶€
    final hasButton = _hasText || _isRecording;

    // ChatGPT ìŠ¤íƒ€ì¼: SafeArea + ì—¬ìœ  íŒ¨ë”© (í‚¤ë³´ë“œ ì—†ì„ ë•Œ ë” ìœ„ë¡œ)
    final bottomPadding = keyboardHeight > 0
        ? keyboardHeight + 8
        : bottomSafeArea + 24;

    return AnimatedPositioned(
      duration: const Duration(milliseconds: 300),
      curve: Curves.easeInOut,
      bottom: bottomPadding,
      left: 16,
      right: 16,
      child: Row(
        crossAxisAlignment: CrossAxisAlignment.center,
        children: [
            // ì™¼ìª½: íƒ€ì›í˜• ì…ë ¥ë€
            Expanded(
              child: Container(
                height: 48,
                decoration: BoxDecoration(
                  color: isDark ? Colors.grey[800] : Colors.grey[200],
                  borderRadius: BorderRadius.circular(24),
                ),
                child: Row(
                children: [
                  // TextField (í•­ìƒ í‘œì‹œ)
                  Expanded(
                    child: Padding(
                      padding: const EdgeInsets.only(left: 20, right: 8),
                      child: TextField(
                        controller: _textController,
                        style: DSTypography.bodyMedium.copyWith(
                          color: isDark ? Colors.white : Colors.black,
                        ),
                        decoration: InputDecoration(
                          hintText: _isRecording ? 'ë“£ê³  ìˆì–´ìš”...' : 'ë¬´ìŠ¨ ê¿ˆì´ì—ˆë‚˜ìš”?',
                          hintStyle: DSTypography.bodyMedium.copyWith(
                            color: _isRecording 
                                ? (isDark ? const Color(0xFF6B4EFF) : const Color(0xFF5835E8)) // ë…¹ìŒ ì¤‘ íŒíŠ¸ ìƒ‰ìƒ ê°•ì¡°
                                : (isDark ? Colors.grey[500] : Colors.grey[600]),
                          ),
                          border: InputBorder.none,
                          enabledBorder: InputBorder.none,
                          focusedBorder: InputBorder.none,
                          disabledBorder: InputBorder.none,
                          filled: false,
                          contentPadding: const EdgeInsets.symmetric(vertical: 14),
                          isDense: true,
                        ),
                        maxLines: 1,
                        // ë…¹ìŒ ì¤‘ì¼ ë•ŒëŠ” ì½ê¸° ì „ìš©ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ, 
                        // ì‚¬ìš©ìê°€ ìˆ˜ì •í•˜ê³  ì‹¶ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í™œì„±í™” ìœ ì§€
                      ),
                    ),
                  ),

                  // ë…¹ìŒ ì¤‘ì¼ ë•Œ ìŠ¤í™íŠ¸ëŸ¼ ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ
                  if (_isRecording)
                    Padding(
                      padding: const EdgeInsets.only(right: 12),
                      child: ValueListenableBuilder<double>(
                        valueListenable: _speechService.soundLevelNotifier,
                        builder: (context, soundLevel, child) {
                          return VoiceSpectrumAnimation(
                            isRecording: _isRecording,
                            barCount: 5,
                            soundLevel: soundLevel,
                            isSpeaking: _isSpeaking,
                          );
                        },
                      ),
                    ),

                  // ë§ˆì´í¬ ë²„íŠ¼ (í…ìŠ¤íŠ¸ ì—†ê³  ë…¹ìŒ ì•ˆí•  ë•Œë§Œ)
                  if (!_hasText && !_isRecording)
                    IconButton(
                      icon: Icon(
                        Icons.mic_none,
                        color: isDark ? Colors.white : Colors.black,
                        size: 24,
                      ),
                      onPressed: _startRecording,
                    ),
                  ],
                ),
              ),
            ),

            // ì˜¤ë¥¸ìª½: ì „ì†¡/ì •ì§€ ë²„íŠ¼ (í…ìŠ¤íŠ¸ ìˆê±°ë‚˜ ë…¹ìŒ ì¤‘ì¼ ë•Œë§Œ)
            if (hasButton) ...[
              const SizedBox(width: 8),
              GestureDetector(
                onTap: _isRecording ? _stopRecordingAndSend : _sendText,
                child: Container(
                  width: 48,
                  height: 48,
                  decoration: BoxDecoration(
                    color: _isRecording 
                        ? (isDark ? Colors.red[400] : Colors.red) // ë…¹ìŒ ì¤‘ì§€ ë²„íŠ¼ì€ ë¹¨ê°„ìƒ‰ ê³„ì—´
                        : (isDark ? Colors.white : Colors.black),
                    shape: BoxShape.circle,
                  ),
                  child: Icon(
                    _isRecording ? Icons.stop : Icons.arrow_upward,
                    color: _isRecording 
                        ? Colors.white 
                        : (isDark ? Colors.black : Colors.white),
                    size: 22,
                  ),
                ),
              ),
            ],
          ],
        ),
    );
  }
}
