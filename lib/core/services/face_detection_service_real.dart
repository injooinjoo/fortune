// face_detection_service_real.dart
// ì‹¤ì œ ê¸°ê¸°ìš© - MediaPipe ì‚¬ìš©

import 'dart:io';
import 'dart:typed_data';
import 'dart:ui';
import 'dart:developer' as developer;
import 'package:mediapipe_face_mesh/mediapipe_face_mesh.dart';

// Re-export MediaPipe types
export 'package:mediapipe_face_mesh/mediapipe_face_mesh.dart'
    show FaceMeshLandmark, MpFaceMeshTriangle;

/// ì–¼êµ´ ê°ì§€ ê²°ê³¼ ëª¨ë¸ (MediaPipe 468 ëœë“œë§ˆí¬ ê¸°ë°˜)
class FaceDetectionResult {
  /// ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (ì •ê·œí™”ëœ ê°’ 0.0 ~ 1.0)
  final double x;
  final double y;
  final double width;
  final double height;

  /// ê°ì§€ ì‹ ë¢°ë„ (0.0 ~ 1.0)
  final double confidence;

  /// ê°ì§€ëœ ì–¼êµ´ ìˆ˜
  final int faceCount;

  /// 468ê°œ ì–¼êµ´ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ (ì •ê·œí™”ëœ ì¢Œí‘œ)
  final List<Offset>? landmarks;

  /// 3D ëœë“œë§ˆí¬ (x, y, z)
  final List<FaceMeshLandmark>? landmarks3D;

  /// ë©”ì‰¬ ì‚¼ê°í˜• ì¸ë±ìŠ¤
  final List<MpFaceMeshTriangle>? triangles;

  const FaceDetectionResult({
    required this.x,
    required this.y,
    required this.width,
    required this.height,
    required this.confidence,
    this.faceCount = 1,
    this.landmarks,
    this.landmarks3D,
    this.triangles,
  });

  /// ë°”ìš´ë”© ë°•ìŠ¤ Rect ë°˜í™˜ (ì •ê·œí™”ëœ ì¢Œí‘œ)
  Rect get boundingBox => Rect.fromLTWH(x, y, width, height);

  /// MediaPipe FaceMeshResultì—ì„œ ìƒì„±
  factory FaceDetectionResult.fromMediaPipe(FaceMeshResult result) {
    // 468 ëœë“œë§ˆí¬ì—ì„œ 2D ì¢Œí‘œ ì¶”ì¶œ
    final landmarks2D = result.landmarks
        .map((lm) => Offset(lm.x, lm.y))
        .toList();

    // ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° (ëœë“œë§ˆí¬ì—ì„œ)
    double minX = 1.0, minY = 1.0, maxX = 0.0, maxY = 0.0;
    for (final lm in result.landmarks) {
      if (lm.x < minX) minX = lm.x;
      if (lm.y < minY) minY = lm.y;
      if (lm.x > maxX) maxX = lm.x;
      if (lm.y > maxY) maxY = lm.y;
    }

    return FaceDetectionResult(
      x: minX,
      y: minY,
      width: maxX - minX,
      height: maxY - minY,
      confidence: result.score,
      faceCount: 1,
      landmarks: landmarks2D,
      landmarks3D: result.landmarks,
      triangles: result.triangles,
    );
  }

  /// ì£¼ìš” ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (MediaPipe Face Mesh ê¸°ì¤€)
  static const int noseTip = 1;
  static const int leftEyeInner = 133;
  static const int leftEyeOuter = 33;
  static const int rightEyeInner = 362;
  static const int rightEyeOuter = 263;
  static const int leftEyeCenter = 159;
  static const int rightEyeCenter = 386;
  static const int mouthLeft = 61;
  static const int mouthRight = 291;
  static const int mouthTop = 13;
  static const int mouthBottom = 14;
  static const int leftCheek = 50;
  static const int rightCheek = 280;
  static const int chinCenter = 152;
  static const int foreheadCenter = 10;

  @override
  String toString() =>
      'FaceDetectionResult(confidence: ${confidence.toStringAsFixed(2)}, landmarks: ${landmarks?.length ?? 0} points)';
}

/// MediaPipe Face Mesh ê¸°ë°˜ ì–¼êµ´ ê°ì§€ ì„œë¹„ìŠ¤
/// iOS & Android: MediaPipe Face Mesh (468 ëœë“œë§ˆí¬, ì‹¤ì‹œê°„ ê°ì§€)
/// ì‹œë®¬ë ˆì´í„°ì—ì„œëŠ” MediaPipe ë¯¸ì§€ì› (ì¹´ë©”ë¼ë§Œ í‘œì‹œ)
class FaceDetectionService {
  /// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
  static final FaceDetectionService _instance =
      FaceDetectionService._internal();
  factory FaceDetectionService() => _instance;
  FaceDetectionService._internal();

  FaceMeshProcessor? _processor;
  bool _isInitialized = false;
  bool _isProcessing = false;
  bool _isSimulator = false;
  bool _isMeshAvailable = false;

  /// ì‹œë®¬ë ˆì´í„° ê°ì§€
  bool _checkIsSimulator() {
    // iOS ì‹œë®¬ë ˆì´í„° ê°ì§€
    if (Platform.isIOS) {
      final env = Platform.environment;
      return env.containsKey('SIMULATOR_DEVICE_NAME') ||
          env.containsKey('SIMULATOR_HOST_HOME');
    }
    // Android ì—ë®¬ë ˆì´í„° ê°ì§€
    if (Platform.isAndroid) {
      final env = Platform.environment;
      return env.containsKey('ANDROID_EMULATOR') ||
          env['ANDROID_SDK_ROOT']?.contains('emulator') == true;
    }
    return false;
  }

  /// ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
  Future<void> initialize() async {
    if (_isInitialized) return;

    _isSimulator = _checkIsSimulator();

    // ì‹œë®¬ë ˆì´í„°ì—ì„œëŠ” MediaPipe ì´ˆê¸°í™” ìŠ¤í‚µ
    if (_isSimulator) {
      developer.log('ğŸ“± ì‹œë®¬ë ˆì´í„° ê°ì§€: Face Mesh ë¹„í™œì„±í™” (ì¹´ë©”ë¼ë§Œ í‘œì‹œ)');
      _isInitialized = true;
      _isMeshAvailable = false;
      return;
    }

    try {
      developer.log('ğŸš€ MediaPipe: ì´ˆê¸°í™” ì‹œì‘');

      // iOS: xnnpack (Metal ëŒ€ì‹ ), Android: gpuV2
      _processor = await FaceMeshProcessor.create(
        delegate: Platform.isIOS
            ? FaceMeshDelegate.xnnpack
            : FaceMeshDelegate.gpuV2,
        threads: 2,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
        enableSmoothing: true,
        enableRoiTracking: true,
      );

      _isInitialized = true;
      _isMeshAvailable = true;
      developer.log('âœ… MediaPipe: ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (e) {
      developer.log('âŒ MediaPipe: ì´ˆê¸°í™” ì‹¤íŒ¨ - $e');

      // GPU ì‹¤íŒ¨ ì‹œ CPU í´ë°±
      try {
        developer.log('ğŸ”„ MediaPipe: CPU í´ë°± ì‹œë„');
        _processor = await FaceMeshProcessor.create(
          delegate: FaceMeshDelegate.cpu,
          threads: 2,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5,
          enableSmoothing: true,
          enableRoiTracking: true,
        );
        _isInitialized = true;
        _isMeshAvailable = true;
        developer.log('âœ… MediaPipe: CPU í´ë°± ì„±ê³µ');
      } catch (e2) {
        developer.log('âŒ MediaPipe: CPU í´ë°±ë„ ì‹¤íŒ¨ - $e2 (ì‹œë®¬ë ˆì´í„°ì¼ ìˆ˜ ìˆìŒ)');
        // ì‹¤íŒ¨í•´ë„ ì´ˆê¸°í™” ì™„ë£Œ ì²˜ë¦¬ (ì¹´ë©”ë¼ë§Œ ì‚¬ìš©)
        _isInitialized = true;
        _isMeshAvailable = false;
      }
    }
  }

  /// í”Œë«í¼ì—ì„œ ì–¼êµ´ ê°ì§€ ì§€ì› ì—¬ë¶€
  Future<bool> isSupported() async {
    return _isMeshAvailable;
  }

  /// Face Mesh ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
  bool get isMeshAvailable => _isMeshAvailable;

  /// ì‹œë®¬ë ˆì´í„° ì—¬ë¶€
  bool get isSimulator => _isSimulator;

  /// iOSìš©: BGRA ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ì–¼êµ´ ê°ì§€
  FaceDetectionResult? detectFromBGRA({
    required Uint8List bytes,
    required int width,
    required int height,
    int rotationDegrees = 0,
    bool mirrorHorizontal = false,
  }) {
    if (!_isInitialized || _isProcessing || _processor == null || !_isMeshAvailable) {
      return null;
    }

    _isProcessing = true;

    try {
      developer.log('ğŸ” MediaPipe: BGRA ì²˜ë¦¬ ì‹œì‘ (${width}x$height)');

      final image = FaceMeshImage(
        pixels: bytes,
        width: width,
        height: height,
        pixelFormat: FaceMeshPixelFormat.bgra,
      );

      final result = _processor!.process(
        image,
        boxScale: 1.5,
        boxMakeSquare: true,
        rotationDegrees: rotationDegrees,
        mirrorHorizontal: mirrorHorizontal,
      );

      if (result.landmarks.isEmpty) {
        developer.log('âšª MediaPipe: ì–¼êµ´ ë¯¸ê°ì§€');
        return null;
      }

      developer.log('âœ… MediaPipe: ì–¼êµ´ ê°ì§€ë¨ (${result.landmarks.length} landmarks, score: ${result.score})');
      return FaceDetectionResult.fromMediaPipe(result);
    } catch (e) {
      developer.log('âŒ MediaPipe: ê°ì§€ ì˜¤ë¥˜ - $e');
      return null;
    } finally {
      _isProcessing = false;
    }
  }

  /// Androidìš©: NV21 ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ì–¼êµ´ ê°ì§€
  FaceDetectionResult? detectFromNV21({
    required Uint8List yPlane,
    required Uint8List vuPlane,
    required int width,
    required int height,
    int? yBytesPerRow,
    int? vuBytesPerRow,
    int rotationDegrees = 0,
    bool mirrorHorizontal = false,
  }) {
    if (!_isInitialized || _isProcessing || _processor == null || !_isMeshAvailable) {
      return null;
    }

    _isProcessing = true;

    try {
      developer.log('ğŸ” MediaPipe: NV21 ì²˜ë¦¬ ì‹œì‘ (${width}x$height)');

      final image = FaceMeshNv21Image(
        yPlane: yPlane,
        vuPlane: vuPlane,
        width: width,
        height: height,
        yBytesPerRow: yBytesPerRow,
        vuBytesPerRow: vuBytesPerRow,
      );

      final result = _processor!.processNv21(
        image,
        boxScale: 1.5,
        boxMakeSquare: true,
        rotationDegrees: rotationDegrees,
        mirrorHorizontal: mirrorHorizontal,
      );

      if (result.landmarks.isEmpty) {
        developer.log('âšª MediaPipe: ì–¼êµ´ ë¯¸ê°ì§€');
        return null;
      }

      developer.log('âœ… MediaPipe: ì–¼êµ´ ê°ì§€ë¨ (${result.landmarks.length} landmarks, score: ${result.score})');
      return FaceDetectionResult.fromMediaPipe(result);
    } catch (e) {
      developer.log('âŒ MediaPipe: ê°ì§€ ì˜¤ë¥˜ - $e');
      return null;
    } finally {
      _isProcessing = false;
    }
  }

  /// YUV420ìš©: ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì–¼êµ´ ê°ì§€ (ë²”ìš©)
  FaceDetectionResult? detectFromYUV420({
    required Uint8List yPlane,
    required Uint8List? uPlane,
    required Uint8List? vPlane,
    required int width,
    required int height,
    required int yRowStride,
    required int uvRowStride,
    required int uvPixelStride,
    int rotationDegrees = 0,
    bool mirrorHorizontal = false,
  }) {
    if (!_isInitialized || _isProcessing || _processor == null || !_isMeshAvailable) {
      return null;
    }

    _isProcessing = true;

    try {
      // YUV420ì„ NV21 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (VU ì¸í„°ë¦¬ë¸Œ)
      final vuPlane = _convertYUV420toVUPlane(
        uPlane: uPlane,
        vPlane: vPlane,
        width: width,
        height: height,
        uvRowStride: uvRowStride,
        uvPixelStride: uvPixelStride,
      );

      final image = FaceMeshNv21Image(
        yPlane: yPlane,
        vuPlane: vuPlane,
        width: width,
        height: height,
        yBytesPerRow: yRowStride,
        vuBytesPerRow: width,
      );

      final result = _processor!.processNv21(
        image,
        boxScale: 1.5,
        boxMakeSquare: true,
        rotationDegrees: rotationDegrees,
        mirrorHorizontal: mirrorHorizontal,
      );

      if (result.landmarks.isEmpty) {
        return null;
      }

      return FaceDetectionResult.fromMediaPipe(result);
    } catch (e) {
      developer.log('âŒ MediaPipe: YUV420 ê°ì§€ ì˜¤ë¥˜ - $e');
      return null;
    } finally {
      _isProcessing = false;
    }
  }

  /// YUV420 U/V í‰ë©´ì„ NV21 VU ì¸í„°ë¦¬ë¸Œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  Uint8List _convertYUV420toVUPlane({
    required Uint8List? uPlane,
    required Uint8List? vPlane,
    required int width,
    required int height,
    required int uvRowStride,
    required int uvPixelStride,
  }) {
    final uvHeight = height ~/ 2;
    final uvWidth = width ~/ 2;
    final vuPlane = Uint8List(width * uvHeight);

    if (uPlane == null || vPlane == null) {
      return vuPlane;
    }

    int vuIndex = 0;
    for (int y = 0; y < uvHeight; y++) {
      for (int x = 0; x < uvWidth; x++) {
        final uvOffset = y * uvRowStride + x * uvPixelStride;
        vuPlane[vuIndex++] = vPlane[uvOffset]; // V first
        vuPlane[vuIndex++] = uPlane[uvOffset]; // then U
      }
    }

    return vuPlane;
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _processor?.close();
    _processor = null;
    _isInitialized = false;
    developer.log('ğŸ§¹ MediaPipe: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ');
  }

  /// í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
  bool get isProcessing => _isProcessing;

  /// ì´ˆê¸°í™” ì™„ë£Œ ì—¬ë¶€
  bool get isInitialized => _isInitialized;

  /// ê°€ì´ë“œ ëª¨ë“œì¸ì§€ í™•ì¸ (MediaPipeëŠ” ì‹¤ì‹œê°„ ì§€ì›í•˜ë¯€ë¡œ í•­ìƒ false)
  bool get isGuideMode => false;
}
