import 'package:flutter/material.dart';
import '../design_system/design_system.dart';
import '../utils/haptic_utils.dart';
import '../../services/speech_recognition_service.dart';
import '../../features/fortune/presentation/widgets/voice_spectrum_animation.dart';

/// ìŒì„± ì…ë ¥ì´ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ í•„ë“œì˜ ìƒíƒœ
enum VoiceInputState {
  /// ê¸°ë³¸ ìƒíƒœ: TextField + ë§ˆì´í¬ ì•„ì´ì½˜
  idle,

  /// ë…¹ìŒ ì¤‘: ì›¨ì´ë¸Œí¼ + ì •ì§€ ë²„íŠ¼
  recording,

  /// ë³€í™˜ ì¤‘: "Transcribing" + ë¡œë”© ìŠ¤í”¼ë„ˆ + ì •ì§€ ë²„íŠ¼
  transcribing,

  /// í…ìŠ¤íŠ¸ ìˆìŒ: TextField + ì „ì†¡ ë²„íŠ¼
  hasText,
}

/// ChatGPT ìŠ¤íƒ€ì¼ì˜ ìŒì„± ì…ë ¥ í…ìŠ¤íŠ¸ í•„ë“œ
///
/// ë ˆì´ì•„ì›ƒ: [ì™¼ìª½ ë²„íŠ¼] [ê°€ìš´ë° pill] [ì˜¤ë¥¸ìª½ ë²„íŠ¼]
class VoiceInputTextField extends StatefulWidget {
  /// í…ìŠ¤íŠ¸ ì „ì†¡ ì‹œ í˜¸ì¶œë˜ëŠ” ì½œë°±
  final Function(String text) onSubmit;

  /// ê¸°ë³¸ ìƒíƒœì˜ íŒíŠ¸ í…ìŠ¤íŠ¸
  final String hintText;

  /// ë³€í™˜ ì¤‘ í‘œì‹œ í…ìŠ¤íŠ¸
  final String transcribingText;

  /// ì™¸ë¶€ì—ì„œ ì£¼ì…í•˜ëŠ” TextEditingController (ì„ íƒ)
  final TextEditingController? controller;

  /// í™œì„±í™” ì—¬ë¶€
  final bool enabled;

  const VoiceInputTextField({
    super.key,
    required this.onSubmit,
    this.hintText = 'Ask anything',
    this.transcribingText = 'Transcribing',
    this.controller,
    this.enabled = true,
  });

  @override
  State<VoiceInputTextField> createState() => _VoiceInputTextFieldState();
}

class _VoiceInputTextFieldState extends State<VoiceInputTextField>
    with SingleTickerProviderStateMixin {
  late TextEditingController _textController;
  final SpeechRecognitionService _speechService = SpeechRecognitionService();

  VoiceInputState _state = VoiceInputState.idle;
  bool _isSpeaking = false; // ì‹¤ì œ ìŒì„± ì¸ì‹ ì¤‘ì¸ì§€ (partial result ìˆ˜ì‹ )

  // ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ìš©
  late AnimationController _loadingController;

  @override
  void initState() {
    super.initState();
    _textController = widget.controller ?? TextEditingController();

    // í…ìŠ¤íŠ¸ ë³€í™” ê°ì§€
    _textController.addListener(_onTextChanged);

    // ì„œë¹„ìŠ¤ ìƒíƒœ ë³€í™” ê°ì§€ (UI ë™ê¸°í™”)
    _speechService.isListeningNotifier.addListener(_onListeningStateChanged);

    // ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ ì»¨íŠ¸ë¡¤ëŸ¬
    _loadingController = AnimationController(
      vsync: this,
      duration: const Duration(milliseconds: 1000),
    )..repeat();
  }

  /// ì„œë¹„ìŠ¤ ìƒíƒœê°€ ë³€ê²½ë˜ë©´ UI ë™ê¸°í™”
  void _onListeningStateChanged() {
    if (!_speechService.isListeningNotifier.value && mounted) {
      // ì„œë¹„ìŠ¤ê°€ ì¤‘ì§€ë˜ì—ˆëŠ”ë° UIê°€ ì•„ì§ recording ìƒíƒœë©´ ë³µêµ¬
      if (_state == VoiceInputState.recording || _state == VoiceInputState.transcribing) {
        final text = _textController.text.trim();
        // í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ hasText, ì—†ìœ¼ë©´ idleë¡œ ë³µêµ¬
        if (text.isNotEmpty) {
          setState(() => _state = VoiceInputState.hasText);
        }
        // í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìë™ ì¬ì‹œì‘ì´ ì²˜ë¦¬í•¨ (idleë¡œ ê°€ì§€ ì•ŠìŒ)
      }
    }
  }

  @override
  void dispose() {
    if (widget.controller == null) {
      _textController.dispose();
    }
    _textController.removeListener(_onTextChanged);
    _speechService.isListeningNotifier.removeListener(_onListeningStateChanged);
    _loadingController.dispose();
    _speechService.dispose();
    super.dispose();
  }

  void _onTextChanged() {
    final hasText = _textController.text.isNotEmpty;

    // idle ë˜ëŠ” hasText ìƒíƒœì—ì„œë§Œ ì „í™˜
    if (_state == VoiceInputState.idle && hasText) {
      setState(() => _state = VoiceInputState.hasText);
    } else if (_state == VoiceInputState.hasText && !hasText) {
      setState(() => _state = VoiceInputState.idle);
    }
  }

  /// ë§ˆì´í¬ ë²„íŠ¼ íƒ­ - ë…¹ìŒ ì‹œì‘
  Future<void> _startRecording() async {
    if (!widget.enabled) return;

    HapticUtils.lightImpact();

    // 1. ê¶Œí•œ í™•ì¸
    final permissionStatus = await _speechService.checkPermissionStatus();

    if (permissionStatus != MicrophonePermissionStatus.granted) {
      if (!mounted) return;
      await _showPermissionDialog(permissionStatus);
      return;
    }

    // 2. ë…¹ìŒ ì‹œì‘
    setState(() {
      _state = VoiceInputState.recording;
      _isSpeaking = false;
      _textController.clear();
    });

    await _startListeningWithAutoRestart();
  }

  /// ìë™ ì¬ì‹œì‘ ì§€ì›í•˜ëŠ” ìŒì„± ì¸ì‹ ì‹œì‘
  Future<void> _startListeningWithAutoRestart() async {
    await _speechService.startListening(
      onResult: (text) {
        // Final result - ë³€í™˜ ì™„ë£Œ
        if (text.isNotEmpty && mounted) {
          setState(() {
            _state = VoiceInputState.hasText;
            _isSpeaking = false;
            _textController.text = text;
            _textController.selection = TextSelection.fromPosition(
              TextPosition(offset: text.length),
            );
          });
        }
      },
      onPartialResult: (text) {
        // Partial result - ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (transcribing ìƒíƒœë¡œ ì „í™˜)
        if (text.isNotEmpty && mounted) {
          setState(() {
            _isSpeaking = true; // ë§í•˜ëŠ” ì¤‘!
            if (_state == VoiceInputState.recording) {
              _state = VoiceInputState.transcribing;
            }
          });
          _textController.text = text;
          _textController.selection = TextSelection.fromPosition(
            TextPosition(offset: text.length),
          );
        }
      },
      onNoMatch: () {
        // error_no_match ë°œìƒ ì‹œ ìë™ ì¬ì‹œì‘
        if (mounted && (_state == VoiceInputState.recording || _state == VoiceInputState.transcribing)) {
          debugPrint('ğŸ¤ [UI] Auto-restarting after no_match');
          _startListeningWithAutoRestart();
        } else {
          // stop ë²„íŠ¼ ëˆŒë €ê±°ë‚˜ mounted ì•„ë‹ˆë©´ idleë¡œ ë³µêµ¬
          if (mounted) {
            setState(() => _state = VoiceInputState.idle);
          }
        }
      },
    );
  }

  /// ì •ì§€ ë²„íŠ¼ íƒ­ - ë…¹ìŒ/ë³€í™˜ ì¤‘ì§€
  Future<void> _stopRecording() async {
    HapticUtils.lightImpact();

    await _speechService.stopListening();

    if (!mounted) return;

    final text = _textController.text.trim();
    setState(() {
      _state = text.isEmpty ? VoiceInputState.idle : VoiceInputState.hasText;
    });
  }

  /// ì „ì†¡ ë²„íŠ¼ íƒ­
  void _submit() {
    HapticUtils.lightImpact();

    final text = _textController.text.trim();
    if (text.isEmpty) return;

    widget.onSubmit(text);

    // ì´ˆê¸°í™”
    _textController.clear();
    setState(() => _state = VoiceInputState.idle);
  }

  /// ê¶Œí•œ ìš”ì²­ ë‹¤ì´ì–¼ë¡œê·¸
  Future<void> _showPermissionDialog(MicrophonePermissionStatus status) async {
    final isDark = Theme.of(context).brightness == Brightness.dark;

    await showDialog<void>(
      context: context,
      builder: (context) => AlertDialog(
        backgroundColor: isDark ? Colors.grey[900] : Colors.white,
        shape: RoundedRectangleBorder(borderRadius: BorderRadius.circular(16)),
        title: Row(
          children: [
            Icon(Icons.mic, color: isDark ? Colors.white : Colors.black),
            const SizedBox(width: 8),
            Text(
              'ë§ˆì´í¬ ê¶Œí•œ í•„ìš”',
              style: TextStyle(
                color: isDark ? Colors.white : Colors.black,
                fontWeight: FontWeight.w600,
              ),
            ),
          ],
        ),
        content: Text(
          'ìŒì„± ì…ë ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
          style: TextStyle(
            color: isDark ? Colors.grey[300] : Colors.grey[700],
          ),
        ),
        actions: [
          TextButton(
            onPressed: () => Navigator.pop(context),
            child: Text(
              'ì·¨ì†Œ',
              style: TextStyle(
                color: isDark ? Colors.grey[400] : Colors.grey[600],
              ),
            ),
          ),
          ElevatedButton(
            onPressed: () async {
              final scaffoldMessenger = ScaffoldMessenger.of(context);
              Navigator.pop(context);

              if (status == MicrophonePermissionStatus.permanentlyDenied) {
                await _speechService.openSettings();
              } else {
                final result = await _speechService.requestPermission();
                if (result == MicrophonePermissionStatus.granted) {
                  _startRecording();
                } else if (result ==
                    MicrophonePermissionStatus.permanentlyDenied) {
                  if (mounted) {
                    scaffoldMessenger.showSnackBar(
                      SnackBar(
                        content: const Text('ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”'),
                        action: SnackBarAction(
                          label: 'ì„¤ì • ì—´ê¸°',
                          onPressed: () => _speechService.openSettings(),
                        ),
                      ),
                    );
                  }
                }
              }
            },
            style: ElevatedButton.styleFrom(
              backgroundColor: isDark ? Colors.white : Colors.black,
              foregroundColor: isDark ? Colors.black : Colors.white,
              shape: RoundedRectangleBorder(
                borderRadius: BorderRadius.circular(8),
              ),
            ),
            child: Text(
              status == MicrophonePermissionStatus.permanentlyDenied
                  ? 'ì„¤ì •ìœ¼ë¡œ ì´ë™'
                  : 'ê¶Œí•œ í—ˆìš©í•˜ê¸°',
            ),
          ),
        ],
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    final isDark = Theme.of(context).brightness == Brightness.dark;
    final isRecordingOrTranscribing =
        _state == VoiceInputState.recording || _state == VoiceInputState.transcribing;

    return Row(
      crossAxisAlignment: CrossAxisAlignment.center,
      children: [
        // ì™¼ìª½: ì •ì§€ ë²„íŠ¼ (recording/transcribing ìƒíƒœì—ì„œë§Œ)
        if (isRecordingOrTranscribing) ...[
          _buildStopButton(isDark),
          const SizedBox(width: 8),
        ],

        // ê°€ìš´ë°: pill ëª¨ì–‘ ì…ë ¥ ì˜ì—­
        Expanded(
          child: Container(
            height: 48,
            decoration: BoxDecoration(
              color: isDark ? Colors.grey[800] : Colors.grey[200],
              borderRadius: BorderRadius.circular(24),
            ),
            child: Row(
              children: [
                // ìƒíƒœì— ë”°ë¥¸ ì½˜í…ì¸ 
                Expanded(child: _buildContent(isDark)),

                // ë§ˆì´í¬ ë²„íŠ¼ (idle ìƒíƒœì—ì„œë§Œ)
                if (_state == VoiceInputState.idle)
                  IconButton(
                    icon: Icon(
                      Icons.mic_none,
                      color: isDark ? Colors.white : Colors.black,
                      size: 24,
                    ),
                    onPressed: widget.enabled ? _startRecording : null,
                  ),
              ],
            ),
          ),
        ),

        // ì˜¤ë¥¸ìª½: ì „ì†¡ ë²„íŠ¼ (hasText ë˜ëŠ” recording/transcribing ìƒíƒœì—ì„œ)
        if (_state == VoiceInputState.hasText || isRecordingOrTranscribing) ...[
          const SizedBox(width: 8),
          _buildSendButton(isDark),
        ],
      ],
    );
  }

  /// ìƒíƒœì— ë”°ë¥¸ ë©”ì¸ ì½˜í…ì¸ 
  Widget _buildContent(bool isDark) {
    switch (_state) {
      case VoiceInputState.idle:
      case VoiceInputState.hasText:
        return _buildTextField(isDark);

      case VoiceInputState.recording:
        return _buildRecordingContent(isDark);

      case VoiceInputState.transcribing:
        return _buildTranscribingContent(isDark);
    }
  }

  /// TextField (idle, hasText ìƒíƒœ)
  Widget _buildTextField(bool isDark) {
    final colors = context.colors;
    final typography = context.typography;

    return Padding(
      padding: const EdgeInsets.only(left: DSSpacing.lg, right: DSSpacing.sm),
      child: TextField(
        controller: _textController,
        enabled: widget.enabled,
        style: typography.bodyMedium.copyWith(
          color: colors.textPrimary,
        ),
        decoration: InputDecoration(
          hintText: widget.hintText,
          hintStyle: typography.bodyMedium.copyWith(
            color: colors.textTertiary,
          ),
          border: InputBorder.none,
          enabledBorder: InputBorder.none,
          focusedBorder: InputBorder.none,
          disabledBorder: InputBorder.none,
          filled: false,
          contentPadding: const EdgeInsets.symmetric(vertical: 14),
          isDense: true,
        ),
        maxLines: 1,
        textInputAction: TextInputAction.send,
        onSubmitted: (_) => _submit(),
      ),
    );
  }

  /// ë…¹ìŒ ì¤‘ ì½˜í…ì¸  (ì›¨ì´ë¸Œí¼)
  Widget _buildRecordingContent(bool isDark) {
    return Padding(
      padding: const EdgeInsets.symmetric(horizontal: 12),
      child: ValueListenableBuilder<double>(
        valueListenable: _speechService.soundLevelNotifier,
        builder: (context, soundLevel, child) {
          return VoiceSpectrumAnimation(
            isRecording: true,
            barCount: 50,
            soundLevel: soundLevel,
            isSpeaking: _isSpeaking,
          );
        },
      ),
    );
  }

  /// ë³€í™˜ ì¤‘ ì½˜í…ì¸  (ë¡œë”© ìŠ¤í”¼ë„ˆ + í…ìŠ¤íŠ¸)
  Widget _buildTranscribingContent(bool isDark) {
    final colors = context.colors;
    final typography = context.typography;

    return Padding(
      padding: const EdgeInsets.symmetric(horizontal: DSSpacing.lg),
      child: Row(
        children: [
          // ë¡œë”© ìŠ¤í”¼ë„ˆ (ì  ê¹œë¹¡ì„)
          AnimatedBuilder(
            animation: _loadingController,
            builder: (context, child) {
              final opacity = 0.3 + (_loadingController.value * 0.7);
              return Icon(
                Icons.auto_awesome,
                size: 16,
                color: colors.textTertiary.withValues(alpha: opacity),
              );
            },
          ),
          const SizedBox(width: DSSpacing.sm),
          Text(
            widget.transcribingText,
            style: typography.bodyMedium.copyWith(
              color: colors.textTertiary,
            ),
          ),
        ],
      ),
    );
  }

  /// ì •ì§€ ë²„íŠ¼ (ì™¼ìª½, íšŒìƒ‰ ìŠ¤íƒ€ì¼)
  Widget _buildStopButton(bool isDark) {
    return GestureDetector(
      onTap: _stopRecording,
      child: Container(
        width: 48,
        height: 48,
        decoration: BoxDecoration(
          color: isDark ? Colors.grey[700] : Colors.grey[300],
          shape: BoxShape.circle,
        ),
        child: Icon(
          Icons.stop,
          color: isDark ? Colors.grey[300] : Colors.grey[700],
          size: 20,
        ),
      ),
    );
  }

  /// ì „ì†¡ ë²„íŠ¼ (ì˜¤ë¥¸ìª½)
  Widget _buildSendButton(bool isDark) {
    final isActive = _state == VoiceInputState.hasText;

    return GestureDetector(
      onTap: isActive ? _submit : null,
      child: Container(
        width: 48,
        height: 48,
        decoration: BoxDecoration(
          color: isActive
              ? (isDark ? Colors.white : Colors.black)
              : (isDark ? Colors.grey[700] : Colors.grey[400]),
          shape: BoxShape.circle,
        ),
        child: Icon(
          Icons.arrow_upward,
          color: isActive
              ? (isDark ? Colors.black : Colors.white)
              : (isDark ? Colors.grey[500] : Colors.grey[600]),
          size: 22,
        ),
      ),
    );
  }
}
