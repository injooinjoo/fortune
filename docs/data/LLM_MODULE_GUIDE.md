# LLM ëª¨ë“ˆ ì‚¬ìš© ê°€ì´ë“œ

**ëª©ì **: LLM Providerë¥¼ ì‰½ê²Œ ì „í™˜í•  ìˆ˜ ìˆëŠ” ì¶”ìƒí™” ëª¨ë“ˆ ì‚¬ìš©ë²•

**ì§€ì› Provider**: OpenAI, Google Gemini, Anthropic Claude

**í•µì‹¬ íŠ¹ì§•**: ì„¤ì • ê¸°ë°˜ Provider ì „í™˜ (ì½”ë“œ ìˆ˜ì • ì—†ìŒ)

---

## ğŸ“‹ ëª©ì°¨

1. [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
2. [ì•„í‚¤í…ì²˜ ê°œìš”](#ì•„í‚¤í…ì²˜-ê°œìš”)
3. [Provider ì „í™˜ ë°©ë²•](#provider-ì „í™˜-ë°©ë²•)
4. [Edge Functionì—ì„œ ì‚¬ìš©](#edge-functionì—ì„œ-ì‚¬ìš©)
5. [ìƒˆ Provider ì¶”ê°€](#ìƒˆ-provider-ì¶”ê°€)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# Supabase Secretsì— Provider ì„¤ì •
supabase secrets set LLM_PROVIDER=gemini
supabase secrets set LLM_DEFAULT_MODEL=gemini-2.0-flash-lite
supabase secrets set GEMINI_API_KEY=your-api-key-here
```

### 2. Edge Functionì—ì„œ ì‚¬ìš©

```typescript
// supabase/functions/fortune-moving/index.ts
import { LLMFactory } from '../_shared/llm/factory.ts'
import { PromptManager } from '../_shared/prompts/manager.ts'

serve(async (req) => {
  // 1. LLM Client ìƒì„± (ì„¤ì •ì—ì„œ ìë™ ì„ íƒ)
  const llm = LLMFactory.createFromConfig('moving')

  // 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
  const promptManager = new PromptManager()
  const prompt = promptManager.getPrompt('moving', {
    name, birthDate, moveDate, direction
  })

  // 3. LLM í˜¸ì¶œ (Provider ë¬´ê´€)
  const response = await llm.generate([
    { role: 'system', content: systemPrompt },
    { role: 'user', content: prompt }
  ], {
    temperature: 1,
    maxTokens: 16000,
    jsonMode: true
  })

  return new Response(JSON.stringify({
    success: true,
    data: JSON.parse(response.content)
  }), {
    headers: { 'Content-Type': 'application/json' }
  })
})
```

### 3. Provider ì „í™˜

```bash
# Geminië¡œ ì „í™˜
supabase secrets set LLM_PROVIDER=gemini

# OpenAIë¡œ ì „í™˜
supabase secrets set LLM_PROVIDER=openai

# ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”! ì¬ë°°í¬ë§Œ í•˜ë©´ ë¨
supabase functions deploy fortune-moving
```

---

## ì•„í‚¤í…ì²˜ ê°œìš”

### í´ë” êµ¬ì¡°

```
supabase/functions/_shared/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ README.md              # ëª¨ë“ˆ ë¬¸ì„œ
â”‚   â”œâ”€â”€ types.ts               # ILLMProvider ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ factory.ts             # LLMFactory (Provider ìƒì„±)
â”‚   â”œâ”€â”€ config.ts              # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ providers/
â”‚       â”œâ”€â”€ README.md          # Provider ì¶”ê°€ ê°€ì´ë“œ
â”‚       â”œâ”€â”€ gemini.ts          # GeminiProvider
â”‚       â”œâ”€â”€ openai.ts          # OpenAIProvider
â”‚       â””â”€â”€ anthropic.ts       # AnthropicProvider (í–¥í›„)
â””â”€â”€ prompts/
    â”œâ”€â”€ README.md              # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ê°€ì´ë“œ
    â”œâ”€â”€ types.ts               # í”„ë¡¬í”„íŠ¸ íƒ€ì…
    â”œâ”€â”€ manager.ts             # PromptManager
    â””â”€â”€ templates/
        â”œâ”€â”€ moving.ts          # ì´ì‚¬ìš´ í”„ë¡¬í”„íŠ¸
        â”œâ”€â”€ tarot.ts           # íƒ€ë¡œ í”„ë¡¬í”„íŠ¸
        â””â”€â”€ ... (27ê°œ ìš´ì„¸)
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

#### 1. ILLMProvider ì¸í„°í˜ì´ìŠ¤

ëª¨ë“  Providerê°€ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ê³µí†µ ì¸í„°í˜ì´ìŠ¤:

```typescript
// _shared/llm/types.ts
export interface ILLMProvider {
  // LLM í˜¸ì¶œ (Provider ë¬´ê´€)
  generate(
    messages: LLMMessage[],
    options?: GenerateOptions
  ): Promise<LLMResponse>

  // ì„¤ì • ê²€ì¦
  validateConfig(): boolean

  // ëª¨ë¸ ì •ë³´
  getModelInfo(): { provider: string; model: string; capabilities: string[] }
}
```

#### 2. LLMFactory

ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ Provider ìƒì„±:

```typescript
// _shared/llm/factory.ts
export class LLMFactory {
  static createFromConfig(fortuneType: string): ILLMProvider {
    const config = getModelConfig(fortuneType)

    switch (config.provider) {
      case 'gemini':
        return new GeminiProvider({
          apiKey: Deno.env.get('GEMINI_API_KEY'),
          model: config.model
        })

      case 'openai':
        return new OpenAIProvider({
          apiKey: Deno.env.get('OPENAI_API_KEY'),
          model: config.model
        })

      default:
        throw new Error(`Unknown provider: ${config.provider}`)
    }
  }
}
```

#### 3. ì„¤ì • ê´€ë¦¬

í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ Provider ì„ íƒ:

```typescript
// _shared/llm/config.ts
export const LLM_GLOBAL_CONFIG = {
  provider: Deno.env.get('LLM_PROVIDER') || 'gemini',
  defaultModel: Deno.env.get('LLM_DEFAULT_MODEL') || 'gemini-2.0-flash-lite',
  defaultTemperature: 1,
  defaultMaxTokens: 8192,
}

// ìš´ì„¸ë³„ ì»¤ìŠ¤í…€ ëª¨ë¸ (ì„ íƒì‚¬í•­)
export const FORTUNE_SPECIFIC_MODELS: Record<string, string | undefined> = {
  'moving': 'gemini-2.0-flash-lite',
  'tarot': 'gemini-2.0-flash-lite',
  // íŠ¹ì • ìš´ì„¸ë§Œ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
}

export function getModelConfig(fortuneType: string) {
  return {
    provider: LLM_GLOBAL_CONFIG.provider,
    model: FORTUNE_SPECIFIC_MODELS[fortuneType] || LLM_GLOBAL_CONFIG.defaultModel,
    temperature: LLM_GLOBAL_CONFIG.defaultTemperature,
    maxTokens: LLM_GLOBAL_CONFIG.defaultMaxTokens,
  }
}
```

---

## Provider ì „í™˜ ë°©ë²•

### ì‹œë‚˜ë¦¬ì˜¤ 1: ëª¨ë“  ìš´ì„¸ë¥¼ Geminië¡œ ì „í™˜

```bash
# 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
supabase secrets set LLM_PROVIDER=gemini
supabase secrets set LLM_DEFAULT_MODEL=gemini-2.0-flash-lite
supabase secrets set GEMINI_API_KEY=your-key-here

# 2. ì „ì²´ í•¨ìˆ˜ ì¬ë°°í¬
supabase functions deploy --all

# 3. ê²€ì¦
curl -X POST https://your-project.supabase.co/functions/v1/fortune-moving \
  -H "Content-Type: application/json" \
  -d '{"name":"í…ŒìŠ¤íŠ¸","birthDate":"1990-01-01",...}'
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: OpenAIë¡œ ë³µê·€

```bash
# 1. í™˜ê²½ë³€ìˆ˜ ë³€ê²½
supabase secrets set LLM_PROVIDER=openai
supabase secrets set LLM_DEFAULT_MODEL=gpt-4o-mini
# OPENAI_API_KEYëŠ” ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ

# 2. ì¬ë°°í¬
supabase functions deploy --all
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: íŠ¹ì • ìš´ì„¸ë§Œ ë‹¤ë¥¸ Provider ì‚¬ìš©

```typescript
// _shared/llm/config.ts ìˆ˜ì •
export const FORTUNE_SPECIFIC_MODELS = {
  'tarot': 'gpt-4o-mini',  // íƒ€ë¡œë§Œ OpenAI ì‚¬ìš©
  // ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ Provider (Gemini) ì‚¬ìš©
}
```

---

## Edge Functionì—ì„œ ì‚¬ìš©

### Before (í•˜ë“œì½”ë”©)

```typescript
// âŒ ë¬¸ì œì : Provider í•˜ë“œì½”ë”©
const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    model: 'gpt-5-nano-2025-08-07',  // í•˜ë“œì½”ë”©!
    messages: [...],
    response_format: { type: 'json_object' },
    temperature: 1,
    max_completion_tokens: 16000
  })
})
```

### After (ëª¨ë“ˆí™”)

```typescript
// âœ… ê°œì„ : Provider ì¶”ìƒí™”
import { LLMFactory } from '../_shared/llm/factory.ts'

const llm = LLMFactory.createFromConfig('moving')

const response = await llm.generate([
  { role: 'system', content: systemPrompt },
  { role: 'user', content: userPrompt }
], {
  temperature: 1,
  maxTokens: 16000,
  jsonMode: true
})

console.log(`âœ… ${response.provider}/${response.model} - ${response.latency}ms`)
```

### í”„ë¡¬í”„íŠ¸ ì¤‘ì•™ ê´€ë¦¬

```typescript
// Before: í”„ë¡¬í”„íŠ¸ í•˜ë“œì½”ë”©
const prompt = `ë‹¹ì‹ ì€ ì´ì‚¬ìš´ì„¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¦„: ${name}
ìƒë…„ì›”ì¼: ${birthDate}
...`

// After: í…œí”Œë¦¿ ì‚¬ìš©
import { PromptManager } from '../_shared/prompts/manager.ts'

const promptManager = new PromptManager()
const prompt = promptManager.getPrompt('moving', {
  name, birthDate, moveDate, direction
})
```

---

## ìƒˆ Provider ì¶”ê°€

### 1. Provider í´ë˜ìŠ¤ ìƒì„±

```typescript
// _shared/llm/providers/anthropic.ts
import { ILLMProvider, LLMMessage, LLMResponse, GenerateOptions } from '../types.ts'

export class AnthropicProvider implements ILLMProvider {
  constructor(private config: { apiKey: string; model: string }) {}

  async generate(
    messages: LLMMessage[],
    options?: GenerateOptions
  ): Promise<LLMResponse> {
    const startTime = Date.now()

    // Anthropic API í˜¸ì¶œ ë¡œì§
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': this.config.apiKey,
        'anthropic-version': '2023-06-01',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: this.config.model,
        messages: messages,
        temperature: options?.temperature ?? 1,
        max_tokens: options?.maxTokens ?? 4096
      })
    })

    const data = await response.json()

    return {
      content: data.content[0].text,
      finishReason: data.stop_reason === 'end_turn' ? 'stop' : 'length',
      usage: {
        promptTokens: data.usage.input_tokens,
        completionTokens: data.usage.output_tokens,
        totalTokens: data.usage.input_tokens + data.usage.output_tokens
      },
      latency: Date.now() - startTime,
      provider: 'anthropic',
      model: this.config.model
    }
  }

  validateConfig(): boolean {
    return !!this.config.apiKey && !!this.config.model
  }

  getModelInfo() {
    return {
      provider: 'anthropic',
      model: this.config.model,
      capabilities: ['text', 'long-context']
    }
  }
}
```

### 2. Factoryì— ë“±ë¡

```typescript
// _shared/llm/factory.ts
import { AnthropicProvider } from './providers/anthropic.ts'

export class LLMFactory {
  static createFromConfig(fortuneType: string): ILLMProvider {
    const config = getModelConfig(fortuneType)

    switch (config.provider) {
      case 'anthropic':  // ì¶”ê°€
        return new AnthropicProvider({
          apiKey: Deno.env.get('ANTHROPIC_API_KEY'),
          model: config.model
        })

      // ... ê¸°ì¡´ caseë“¤
    }
  }
}
```

### 3. í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
supabase secrets set LLM_PROVIDER=anthropic
supabase secrets set LLM_DEFAULT_MODEL=claude-3-5-sonnet-20241022
supabase secrets set ANTHROPIC_API_KEY=your-key-here
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. "Unknown provider" ì—ëŸ¬

**ì¦ìƒ**:
```
Error: Unknown provider: gemini
```

**ì›ì¸**: `LLM_PROVIDER` í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜ëª»ë¨

**í•´ê²°**:
```bash
# í™˜ê²½ë³€ìˆ˜ í™•ì¸
supabase secrets list | grep LLM_PROVIDER

# ì˜¬ë°”ë¥¸ ê°’ìœ¼ë¡œ ì„¤ì •
supabase secrets set LLM_PROVIDER=gemini
```

### 2. API í˜¸ì¶œ ì‹¤íŒ¨

**ì¦ìƒ**:
```
Error: API call failed: 401 Unauthorized
```

**ì›ì¸**: API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë§Œë£Œë¨

**í•´ê²°**:
```bash
# Gemini ì‚¬ìš© ì‹œ
supabase secrets list | grep GEMINI_API_KEY

# í‚¤ê°€ ì—†ìœ¼ë©´ ì„¤ì •
supabase secrets set GEMINI_API_KEY=your-key-here

# OpenAI ì‚¬ìš© ì‹œ
supabase secrets list | grep OPENAI_API_KEY
supabase secrets set OPENAI_API_KEY=your-key-here
```

### 3. JSON íŒŒì‹± ì—ëŸ¬

**ì¦ìƒ**:
```
Error: Unexpected token in JSON
```

**ì›ì¸**: Providerê°€ JSON ì‘ë‹µì„ ë³´ë‚´ì§€ ì•ŠìŒ

**í•´ê²°**:
- `jsonMode: true` ì˜µì…˜ ì‚¬ìš© í™•ì¸
- í”„ë¡¬í”„íŠ¸ì— "JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ" ëª…ì‹œ í™•ì¸
- Providerë³„ JSON ëª¨ë“œ ì§€ì› í™•ì¸

```typescript
// Gemini JSON ëª¨ë“œ
const response = await llm.generate([...], {
  jsonMode: true,  // responseMimeType: 'application/json'
})

// OpenAI JSON ëª¨ë“œ
const response = await llm.generate([...], {
  jsonMode: true,  // response_format: { type: 'json_object' }
})
```

### 4. ëŠë¦° ì‘ë‹µ ì†ë„

**ì¦ìƒ**: API í˜¸ì¶œì´ 10ì´ˆ ì´ìƒ ì†Œìš”

**ì›ì¸**: Reasoning ëª¨ë¸ (GPT-5-nano) ì‚¬ìš© ì¤‘

**í•´ê²°**:
```bash
# Reasoning ëª¨ë¸ ëŒ€ì‹  ì¼ë°˜ ëª¨ë¸ ì‚¬ìš©
supabase secrets set LLM_PROVIDER=gemini
supabase secrets set LLM_DEFAULT_MODEL=gemini-2.0-flash-lite
# ë˜ëŠ”
supabase secrets set LLM_PROVIDER=openai
supabase secrets set LLM_DEFAULT_MODEL=gpt-4o-mini
```

### 5. ë¹„ìš© ê³¼ë‹¤

**ì¦ìƒ**: OpenAI ì²­êµ¬ì•¡ì´ ì˜ˆìƒë³´ë‹¤ ë†’ìŒ

**í•´ê²°**:
1. **Geminië¡œ ì „í™˜** (70% ë¹„ìš© ì ˆê°)
   ```bash
   supabase secrets set LLM_PROVIDER=gemini
   ```

2. **í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§**
   ```typescript
   const response = await llm.generate([...])
   console.log(`ğŸ“Š Tokens: ${response.usage.totalTokens}`)
   ```

3. **ìš´ì„¸ë³„ ëª¨ë¸ ìµœì í™”**
   ```typescript
   // ì§§ì€ ìš´ì„¸ëŠ” ì‘ì€ ëª¨ë¸
   export const FORTUNE_SPECIFIC_MODELS = {
     'fortune-cookie': 'gemini-1.5-flash',  // ì§§ì€ ì‘ë‹µ
     'tarot': 'gemini-2.0-flash-lite',       // ê¸´ ì‘ë‹µ
   }
   ```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [LLM_PROVIDER_MIGRATION.md](./LLM_PROVIDER_MIGRATION.md) - Provider ë³€ê²½ ê°€ì´ë“œ
- [PROMPT_ENGINEERING_GUIDE.md](./PROMPT_ENGINEERING_GUIDE.md) - í”„ë¡¬í”„íŠ¸ ì‘ì„± ê°€ì´ë“œ
- [API_KEY_ROTATION_GUIDE.md](../deployment/API_KEY_ROTATION_GUIDE.md) - API í‚¤ ê´€ë¦¬

---

## ğŸ“ ì§€ì›

### OpenAI
- https://help.openai.com
- API í‚¤ ë¶„ì‹¤ ì‹œ ì¬ë°œê¸‰ í•„ìˆ˜

### Google Gemini
- https://ai.google.dev/docs
- API Console: https://aistudio.google.com/app/apikey

### Anthropic Claude
- https://docs.anthropic.com
- Console: https://console.anthropic.com

---

**ì‘ì„±ì**: Claude Code
**ìµœì¢… ìˆ˜ì •**: 2025-01-10
**ë²„ì „**: 1.0.0
